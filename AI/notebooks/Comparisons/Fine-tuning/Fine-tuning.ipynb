{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bc2c4c",
   "metadata": {
    "papermill": {
     "duration": 0.005291,
     "end_time": "2025-06-08T09:49:18.647738",
     "exception": false,
     "start_time": "2025-06-08T09:49:18.642447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing & Loading Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2198f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:49:18.658831Z",
     "iopub.status.busy": "2025-06-08T09:49:18.658046Z",
     "iopub.status.idle": "2025-06-08T09:50:05.843164Z",
     "shell.execute_reply": "2025-06-08T09:50:05.841939Z"
    },
    "papermill": {
     "duration": 47.193684,
     "end_time": "2025-06-08T09:50:05.846034",
     "exception": false,
     "start_time": "2025-06-08T09:49:18.652350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\r\n",
      "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\r\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\r\n",
      "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: monai\r\n",
      "Successfully installed monai-1.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install monai\n",
    "# !pip install 'monai[nibabel]'\n",
    "\n",
    "import nibabel as nib\n",
    "from monai.transforms import LoadImage, Compose, NormalizeIntensityd, RandSpatialCropd, RandFlipd, \\\n",
    "                             RandRotate90d, Rand3DElasticd, RandAdjustContrastd, CenterSpatialCropd,\\\n",
    "                             Resized, RandRotated, RandZoomd, RandGaussianNoised, Spacingd, RandShiftIntensityd,  CropForegroundd, SpatialPadd, AsDiscrete, GridPatchd\\\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate\n",
    "import pdb\n",
    "\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.networks import one_hot\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "import torchvision\n",
    "import math\n",
    "\n",
    "from grpc import insecure_channel\n",
    "import argparse\n",
    "from torch import optim, amp\n",
    "from monai.losses import DiceLoss\n",
    "import torch.distributed as dist\n",
    "\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import pdb\n",
    "import logging\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f8e1",
   "metadata": {
    "papermill": {
     "duration": 0.005318,
     "end_time": "2025-06-08T09:50:05.860100",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.854782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Dataset with Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f92d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:05.878004Z",
     "iopub.status.busy": "2025-06-08T09:50:05.877269Z",
     "iopub.status.idle": "2025-06-08T09:50:05.897101Z",
     "shell.execute_reply": "2025-06-08T09:50:05.896079Z"
    },
    "papermill": {
     "duration": 0.032194,
     "end_time": "2025-06-08T09:50:05.899284",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.867090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset3D(Dataset):\n",
    "    def __init__(self, data_dir, patient_lists, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.patient_lists = patient_lists\n",
    "        self.mode = mode\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_with_aspect_ratio(keys, target_size):\n",
    "        def transform(data):\n",
    "            for key in keys:\n",
    "                volume = data[key]\n",
    "                original_shape = volume.shape[-3:]\n",
    "    \n",
    "                scaling_factor = min(\n",
    "                    target_size[0] / original_shape[0],\n",
    "                    target_size[1] / original_shape[1],\n",
    "                    target_size[2] / original_shape[2]\n",
    "                )\n",
    "    \n",
    "                # Computing the intermediate size while preserving aspect ratio\n",
    "                new_shape = [\n",
    "                    int(dim * scaling_factor) for dim in original_shape\n",
    "                ]\n",
    "    \n",
    "                # Resizing to the intermediate shape\n",
    "                resize_transform = Resized(keys=[key], spatial_size=new_shape, mode=\"trilinear\" if key == \"imgs\" else \"nearest-exact\")\n",
    "                data = resize_transform(data)\n",
    "    \n",
    "                # Padding to the final target size\n",
    "                pad_transform = SpatialPadd(keys=[key], spatial_size=target_size, mode=\"constant\")\n",
    "                data = pad_transform(data)\n",
    "            return data\n",
    "\n",
    "        return transform\n",
    "    \n",
    "    def preprocess(cls, data, mode):\n",
    "        if mode == 'training':\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True),\n",
    "              \n",
    "            RandFlipd(keys=[\"imgs\", \"masks\"],   \n",
    "                    prob=0.5,                 \n",
    "                    spatial_axis=2,  \n",
    "            ),\n",
    "\n",
    "            RandAdjustContrastd(\n",
    "                keys=[\"imgs\"],          \n",
    "                prob=0.15,             \n",
    "                gamma=(0.65, 1.5),   \n",
    "            ),\n",
    "            \n",
    "        ])\n",
    "\n",
    "        elif mode == 'validation':\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True)\n",
    "\n",
    "        ])\n",
    "\n",
    "        else: # 'testing'\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True)\n",
    "\n",
    "        ])\n",
    "\n",
    "        augmented_data = transform(data)\n",
    "        return augmented_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_lists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_lists[idx]\n",
    "        loadimage = LoadImage(reader='NibabelReader', image_only=True)\n",
    "        data_type=patient_id.split('-')[1]\n",
    "\n",
    "        patient_folder_path = os.path.join(self.data_dir, patient_id)\n",
    "\n",
    "        def resolve_file_path(folder, name):\n",
    "            file_path = os.path.join(folder, name)\n",
    "            # Check if the given path is a directory (case with 4 subdirs)\n",
    "            if os.path.isdir(file_path):\n",
    "                # Find the first file inside the directory that ends with .nii\n",
    "                for root, _, files in os.walk(file_path):\n",
    "                    for file in files:\n",
    "                        if file.endswith(\".nii\"):\n",
    "                            return os.path.join(root, file)\n",
    "            return file_path\n",
    "\n",
    "\n",
    "        # Resolve paths for all required image types\n",
    "        t1c_path  = resolve_file_path(patient_folder_path, patient_id + '-t1c.nii')\n",
    "        t1n_path  = resolve_file_path(patient_folder_path, patient_id + '-t1n.nii')\n",
    "        t2f_path  = resolve_file_path(patient_folder_path, patient_id + '-t2f.nii')\n",
    "        t2w_path  = resolve_file_path(patient_folder_path, patient_id + '-t2w.nii')\n",
    "        seg_path  = os.path.join(patient_folder_path, patient_id + '-seg.nii')\n",
    "\n",
    "        t1c_loader   = loadimage( t1c_path )\n",
    "        t1n_loader   = loadimage( t1n_path )\n",
    "        t2f_loader   = loadimage( t2f_path )\n",
    "        t2w_loader   = loadimage( t2w_path )\n",
    "        masks_loader = loadimage( seg_path )\n",
    "\n",
    "        # Make the dimension of channel\n",
    "        t1c_tensor   = torch.Tensor(t1c_loader).unsqueeze(0)\n",
    "        t1n_tensor   = torch.Tensor(t1n_loader).unsqueeze(0)\n",
    "        t2f_tensor   = torch.Tensor(t2f_loader).unsqueeze(0)\n",
    "        t2w_tensor   = torch.Tensor(t2w_loader).unsqueeze(0)\n",
    "        masks_tensor = torch.Tensor(masks_loader).unsqueeze(0)\n",
    "\n",
    "        # dividing the mask to each class\n",
    "        '''\n",
    "        Output channel\n",
    "        [1, 0, 0, 0] = BackGround (BG)\n",
    "        [0, 1, 0, 0] = Necrosis (NE)\n",
    "        [0, 0, 1, 0] = Edema (ED)\n",
    "        [0, 0, 0, 1] = Enhancing Tumor (ET)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # x = torch.ones( masks_tensor.size() )\n",
    "        # y = torch.zeros( masks_tensor.size() )\n",
    "\n",
    "        # masks_BG = torch.where( masks_tensor == 0, x, y )\n",
    "        # masks_NE = torch.where( masks_tensor == 1, x, y )\n",
    "        # masks_ED = torch.where( masks_tensor == 2, x, y )\n",
    "        # masks_ET = torch.where( masks_tensor == 3, x, y )\n",
    "\n",
    "        concat_tensor = torch.cat( (t1c_tensor, t1n_tensor, t2f_tensor, t2w_tensor, masks_tensor), 0 )\n",
    "\n",
    "        data = {\n",
    "            \n",
    "            'imgs'  : np.array(concat_tensor[0:4,:,:,:]),\n",
    "            'masks' : np.array(concat_tensor[4:,:,:,:])\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        augmented_imgs_masks = self.preprocess(data, self.mode)\n",
    "        imgs  = np.array(augmented_imgs_masks['imgs'])\n",
    "        masks = np.array(augmented_imgs_masks['masks'])\n",
    "\n",
    "        y = {\n",
    "\n",
    "            'imgs'  : torch.from_numpy(imgs).type(torch.FloatTensor),\n",
    "            'masks' : torch.from_numpy(masks).type(torch.FloatTensor),\n",
    "            'patient_id' : patient_id,\n",
    "            'data_type' : data_type\n",
    "\n",
    "        }\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae93ff",
   "metadata": {
    "papermill": {
     "duration": 0.004844,
     "end_time": "2025-06-08T09:50:05.912450",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.907606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b61ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:05.923756Z",
     "iopub.status.busy": "2025-06-08T09:50:05.923405Z",
     "iopub.status.idle": "2025-06-08T09:50:05.931107Z",
     "shell.execute_reply": "2025-06-08T09:50:05.930187Z"
    },
    "papermill": {
     "duration": 0.015352,
     "end_time": "2025-06-08T09:50:05.932828",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.917476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(args):\n",
    "    random.seed(5)\n",
    "    split_ratio = {'training': 0.71, 'validation': 0.09, 'testing': 0.2}\n",
    "    data_dir = args['data_dir']\n",
    "    \n",
    "    patient_lists = os.listdir( data_dir )\n",
    "    patient_lists.sort()\n",
    "    total_patients = len(patient_lists)\n",
    "    \n",
    "    # Shuffle the patient list\n",
    "    random.shuffle(patient_lists)\n",
    "    \n",
    "    train_split = int(split_ratio['training'] * total_patients)\n",
    "    val_split = int(split_ratio['validation'] * total_patients)\n",
    "    \n",
    "    train_patient_lists = patient_lists[:train_split]\n",
    "    val_patient_lists = patient_lists[train_split : train_split + val_split]\n",
    "    test_patient_lists = patient_lists[train_split + val_split :]\n",
    "    \n",
    "    train_patient_lists.sort()\n",
    "    val_patient_lists.sort()\n",
    "    test_patient_lists.sort()\n",
    "    \n",
    "    print(f'Number of training samples', len(train_patient_lists))\n",
    "    print(f'Number of validation samples', len(val_patient_lists))\n",
    "    print(f'Number of testing samples', len(test_patient_lists))\n",
    "\n",
    "    trainDataset = CustomDataset3D( data_dir, train_patient_lists, mode='training')\n",
    "    valDataset   = CustomDataset3D( data_dir, val_patient_lists, mode='validation')\n",
    "    testDataset  = CustomDataset3D( data_dir, test_patient_lists, mode='testing')\n",
    "    \n",
    "    trainLoader = DataLoader(\n",
    "        trainDataset, batch_size=args['train_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=True)\n",
    "    \n",
    "    valLoader = DataLoader(\n",
    "        valDataset, batch_size=args['val_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=False)\n",
    "    \n",
    "    testLoader = DataLoader(\n",
    "        testDataset, batch_size=args['test_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=False)\n",
    "\n",
    "    return trainLoader, valLoader, testLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7dc88a",
   "metadata": {
    "papermill": {
     "duration": 0.004781,
     "end_time": "2025-06-08T09:50:05.942509",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.937728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DynUNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9c0500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:05.953964Z",
     "iopub.status.busy": "2025-06-08T09:50:05.953698Z",
     "iopub.status.idle": "2025-06-08T09:50:05.973826Z",
     "shell.execute_reply": "2025-06-08T09:50:05.972816Z"
    },
    "papermill": {
     "duration": 0.028143,
     "end_time": "2025-06-08T09:50:05.975574",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.947431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN module module that can be used for DynUNet, based on:\n",
    "    `Automated Design of Deep Learning Methods for Biomedical Image Segmentation <https://arxiv.org/abs/1904.08128>`_.\n",
    "    `nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation <https://arxiv.org/abs/1809.10486>`_.\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions.\n",
    "        in_channels: number of input channels.\n",
    "        out_channels: number of output channels.\n",
    "        kernel_size: convolution kernel size.\n",
    "        stride: convolution stride.\n",
    "        norm_name: feature normalization type and arguments.\n",
    "        act_name: activation layer type and arguments.\n",
    "        dropout: dropout probability.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[Sequence[int], int],\n",
    "        stride: Union[Sequence[int], int],\n",
    "        norm_name: Union[Tuple, str] = (\"INSTANCE\", {\"affine\": True}),\n",
    "        act_name: Union[Tuple, str] = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            dropout=dropout,\n",
    "            conv_only=True,\n",
    "        )\n",
    "\n",
    "        self.conv2 = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            dropout=dropout,\n",
    "            conv_only=True\n",
    "        )\n",
    "        self.lrelu = get_act_layer(name=act_name)\n",
    "        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n",
    "        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.conv1(inp)\n",
    "        out = self.norm1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.lrelu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UnetUpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    An upsampling module that can be used for DynUNet, based on:\n",
    "    `Automated Design of Deep Learning Methods for Biomedical Image Segmentation <https://arxiv.org/abs/1904.08128>`_.\n",
    "    `nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation <https://arxiv.org/abs/1809.10486>`_.\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions.\n",
    "        in_channels: number of input channels.\n",
    "        out_channels: number of output channels.\n",
    "        kernel_size: convolution kernel size.\n",
    "        stride: convolution stride.\n",
    "        upsample_kernel_size: convolution kernel size for transposed convolution layers.\n",
    "        norm_name: feature normalization type and arguments.\n",
    "        act_name: activation layer type and arguments.\n",
    "        dropout: dropout probability.\n",
    "        trans_bias: transposed convolution bias.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[Sequence[int], int],\n",
    "        upsample_kernel_size: Union[Sequence[int], int],\n",
    "        norm_name: Union[Tuple, str] = (\"INSTANCE\", {\"affine\": True}),\n",
    "        act_name: Union[Tuple, str] = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "        trans_bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        upsample_stride = upsample_kernel_size\n",
    "        \n",
    "        # ( a purple arrow in the paper )\n",
    "        self.transp_conv = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=upsample_kernel_size,\n",
    "            stride=upsample_stride,\n",
    "            dropout=dropout,\n",
    "            bias=trans_bias,\n",
    "            conv_only=True,\n",
    "            is_transposed=True,\n",
    "        )\n",
    "        \n",
    "        # A light blue conv blocks in the decoder of nnUNet\n",
    "        self.conv_block = UnetBasicBlock(\n",
    "            spatial_dims,\n",
    "            out_channels + out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            dropout=dropout,\n",
    "            norm_name=norm_name,\n",
    "            act_name=act_name,\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, skip):\n",
    "        # number of channels for skip should equals to out_channels\n",
    "        out = self.transp_conv(inp)\n",
    "        out = torch.cat((out, skip), dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UnetOutBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, out_channels: int, dropout: Optional[Union[Tuple, str, float]] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = get_conv_layer(\n",
    "            spatial_dims, in_channels, out_channels, kernel_size=1, stride=1, dropout=dropout, bias=True, conv_only=True\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.conv(inp)\n",
    "    \n",
    "\n",
    "def get_conv_layer(\n",
    "    spatial_dims: int,\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: Union[Sequence[int], int] = 3,\n",
    "    stride: Union[Sequence[int], int] = 1,\n",
    "    act: Optional[Union[Tuple, str]] = Act.PRELU,\n",
    "    norm: Union[Tuple, str] = Norm.INSTANCE,\n",
    "    dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "    bias: bool = False,\n",
    "    conv_only: bool = True,\n",
    "    is_transposed: bool = False,\n",
    "):\n",
    "    padding = get_padding(kernel_size, stride)\n",
    "    output_padding = None\n",
    "    if is_transposed:\n",
    "        output_padding = get_output_padding(kernel_size, stride, padding)\n",
    "    \n",
    "    return Convolution(\n",
    "        spatial_dims,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        strides=stride,\n",
    "        kernel_size=kernel_size,\n",
    "        act=act,\n",
    "        norm=norm,\n",
    "        dropout=dropout,\n",
    "        bias=bias,\n",
    "        conv_only=conv_only,\n",
    "        is_transposed=is_transposed,\n",
    "        padding=padding,\n",
    "        output_padding=output_padding,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_padding(\n",
    "    kernel_size: Union[Sequence[int], int], stride: Union[Sequence[int], int]\n",
    ") -> Union[Tuple[int, ...], int]:\n",
    "\n",
    "    kernel_size_np = np.atleast_1d(kernel_size)\n",
    "    stride_np = np.atleast_1d(stride)\n",
    "    padding_np = (kernel_size_np - stride_np + 1) / 2\n",
    "    if np.min(padding_np) < 0:\n",
    "        raise AssertionError(\"padding value should not be negative, please change the kernel size and/or stride.\")\n",
    "    padding = tuple(int(p) for p in padding_np)\n",
    "\n",
    "    return padding if len(padding) > 1 else padding[0]\n",
    "\n",
    "\n",
    "def get_output_padding(\n",
    "    kernel_size: Union[Sequence[int], int], stride: Union[Sequence[int], int], padding: Union[Sequence[int], int]\n",
    ") -> Union[Tuple[int, ...], int]:\n",
    "    kernel_size_np = np.atleast_1d(kernel_size)\n",
    "    stride_np = np.atleast_1d(stride)\n",
    "    padding_np = np.atleast_1d(padding)\n",
    "\n",
    "    out_padding_np = 2 * padding_np + stride_np - kernel_size_np\n",
    "    if np.min(out_padding_np) < 0:\n",
    "        raise AssertionError(\"out_padding value should not be negative, please change the kernel size and/or stride.\")\n",
    "    out_padding = tuple(int(p) for p in out_padding_np)\n",
    "\n",
    "    return out_padding if len(out_padding) > 1 else out_padding[0]\n",
    "\n",
    "def set_requires_grad(nets, requires_grad=False):\n",
    "    if not isinstance(nets, list):\n",
    "        nets = [nets]\n",
    "    for net in nets:\n",
    "        if net is not None:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed67f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:05.987640Z",
     "iopub.status.busy": "2025-06-08T09:50:05.987213Z",
     "iopub.status.idle": "2025-06-08T09:50:06.009326Z",
     "shell.execute_reply": "2025-06-08T09:50:06.008417Z"
    },
    "papermill": {
     "duration": 0.030875,
     "end_time": "2025-06-08T09:50:06.011601",
     "exception": false,
     "start_time": "2025-06-08T09:50:05.980726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DynUNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        deep_supervision: bool,\n",
    "        KD: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.spatial_dims = spatial_dims\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.deep_supervision = deep_supervision\n",
    "        self.KD_enabled = KD\n",
    "        \n",
    "        self.input_conv = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=self.in_channels,\n",
    "                                     out_channels=64,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1\n",
    "                                     )\n",
    "        self.down1 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=64,\n",
    "                                     out_channels=96,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2 # Reduces spatial dims by 2\n",
    "                                     )\n",
    "        self.down2 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=96,\n",
    "                                     out_channels=128,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down3 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=128,\n",
    "                                     out_channels=192,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down4 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=192,\n",
    "                                     out_channels=256,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down5 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=256,\n",
    "                                     out_channels=384,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.bottleneck = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=384,\n",
    "                                     out_channels=512,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.up1 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=512,\n",
    "                                out_channels=384,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up2 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=384,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up3 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=256,\n",
    "                                out_channels=192,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up4 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=192,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        \n",
    "        self.up5 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=128,\n",
    "                                out_channels=96,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )        \n",
    "        self.up6 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=96,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.out1 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=64,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        self.out2 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=96,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        self.out3 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=128,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        \n",
    "    def forward( self, input ):\n",
    "        \n",
    "        # Input\n",
    "        x0 = self.input_conv( input ) # x0.shape = (B x 64 x 128 x 128 x 128)\n",
    "        \n",
    "        # Encoder\n",
    "        x1 = self.down1( x0 ) # x1.shape = (B x 96 x 64 x 64 x 64) \n",
    "        x2 = self.down2( x1 ) # x2.shape = (B x 128 x 32 x 32 x 32)\n",
    "        x3 = self.down3( x2 ) # x3.shape = (B x 192 x 16 x 16 x 16)\n",
    "        x4 = self.down4( x3 ) # x4.shape = (B x 256 x 8 x 8 x 8)   \n",
    "        x5 = self.down5( x4 ) # x5.shape = (B x 384 x 4 x 4 x 4)   \n",
    "        \n",
    "        # Bottleneck\n",
    "        x6 = self.bottleneck( x5 ) # x6.shape = (B x 512 x 2 x 2 x 2)\n",
    "        \n",
    "        # Decoder\n",
    "        x7  = self.up1( x6, x5 )  # x7.shape  = (B x 384 x 4 x 4 x 4)\n",
    "        x8  = self.up2( x7, x4 )  # x8.shape  = (B x 256 x 8 x 8 x 8)\n",
    "        x9  = self.up3( x8, x3 )  # x9.shape  = (B x 192 x 16 x 16 x 16)\n",
    "        x10 = self.up4( x9, x2 )  # x10.shape = (B x 128 x 32 x 32 x 32)\n",
    "        x11 = self.up5( x10, x1 ) # x11.shape = (B x 96 x 64 x 64 x 64)\n",
    "        x12 = self.up6( x11, x0 ) # x12.shape = (B x 64 x 128 x 128 x 128)\n",
    "        \n",
    "        # Output\n",
    "        output1 = self.out1( x12 )\n",
    "        \n",
    "        if (self.training and self.deep_supervision) or self.KD_enabled:\n",
    "            \n",
    "            # output['pred'].shape = B x 3 x 4 x 128 x 128 x 128\n",
    "            output2 = interpolate( self.out2( x11 ), output1.shape[2:])\n",
    "            output3 = interpolate( self.out3( x10 ), output1.shape[2:])\n",
    "            output_all = [ output1, output2, output3 ]\n",
    "            return { 'pred' : torch.stack(output_all, dim=1),\n",
    "                     'bottleneck_feature_map' : x6 }\n",
    "        \n",
    "        return { 'pred' : output1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ceab1e",
   "metadata": {
    "papermill": {
     "duration": 0.008735,
     "end_time": "2025-06-08T09:50:06.029871",
     "exception": false,
     "start_time": "2025-06-08T09:50:06.021136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualizing Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e0cf5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:06.048580Z",
     "iopub.status.busy": "2025-06-08T09:50:06.048262Z",
     "iopub.status.idle": "2025-06-08T09:50:06.052314Z",
     "shell.execute_reply": "2025-06-08T09:50:06.051472Z"
    },
    "papermill": {
     "duration": 0.01524,
     "end_time": "2025-06-08T09:50:06.053902",
     "exception": false,
     "start_time": "2025-06-08T09:50:06.038662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "# from torchsummary import summary\n",
    "\n",
    "# # Initialize your DynUNet model\n",
    "# model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=True, KD=True)\n",
    "\n",
    "# # Print model summary\n",
    "# summary(model, input_size=(4, 128, 128, 128))  # Adjust input_size according to your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf24fc",
   "metadata": {
    "papermill": {
     "duration": 0.004835,
     "end_time": "2025-06-08T09:50:06.063658",
     "exception": false,
     "start_time": "2025-06-08T09:50:06.058823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62e6025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:06.075157Z",
     "iopub.status.busy": "2025-06-08T09:50:06.074387Z",
     "iopub.status.idle": "2025-06-08T09:50:17.968983Z",
     "shell.execute_reply": "2025-06-08T09:50:17.967986Z"
    },
    "papermill": {
     "duration": 11.902323,
     "end_time": "2025-06-08T09:50:17.970761",
     "exception": false,
     "start_time": "2025-06-08T09:50:06.068438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clearml\r\n",
      "  Downloading clearml-2.0.0-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: attrs>=18.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (23.2.0)\r\n",
      "Collecting furl>=2.0.0 (from clearml)\r\n",
      "  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (4.22.0)\r\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.4)\r\n",
      "Collecting pathlib2>=2.3.0 (from clearml)\r\n",
      "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: psutil>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from clearml) (5.9.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from clearml) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.8.0)\r\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.10/site-packages (from clearml) (6.0.2)\r\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.18)\r\n",
      "Requirement already satisfied: Pillow>=10.3.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (10.3.0)\r\n",
      "Requirement already satisfied: referencing<0.40 in /opt/conda/lib/python3.10/site-packages (from clearml) (0.35.1)\r\n",
      "Requirement already satisfied: requests>=2.32.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.32.3)\r\n",
      "Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\r\n",
      "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (0.18.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (2024.8.30)\r\n",
      "Downloading clearml-2.0.0-py2.py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\r\n",
      "Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: pathlib2, orderedmultidict, furl, clearml\r\n",
      "Successfully installed clearml-2.0.0 furl-2.1.4 orderedmultidict-1.0.1 pathlib2-2.3.7.post1\r\n",
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=0TFL6QYHDZC909YZDW4ZW9HEX58P29\n",
      "env: CLEARML_API_SECRET_KEY=q-gJ-2T1TPot7WFKmrcwlN84T5mPqsL33ozDlF2i8J7j8oQa8xmv0v1H6xIzoIcmpG4\n"
     ]
    }
   ],
   "source": [
    "!pip install clearml\n",
    "from clearml import Task\n",
    "\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=CLEARML_API_ACCESS_KEY\n",
    "%env CLEARML_API_SECRET_KEY=CLEARML_API_SECRET_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab322d7",
   "metadata": {
    "papermill": {
     "duration": 0.005677,
     "end_time": "2025-06-08T09:50:17.982388",
     "exception": false,
     "start_time": "2025-06-08T09:50:17.976711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a998994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:17.995421Z",
     "iopub.status.busy": "2025-06-08T09:50:17.994742Z",
     "iopub.status.idle": "2025-06-08T09:50:18.001630Z",
     "shell.execute_reply": "2025-06-08T09:50:18.000793Z"
    },
    "papermill": {
     "duration": 0.015295,
     "end_time": "2025-06-08T09:50:18.003386",
     "exception": false,
     "start_time": "2025-06-08T09:50:17.988091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.dice = DiceLoss(sigmoid=True, batch=True, smooth_nr=1e-05, smooth_dr=1e-05)\n",
    "        self.ce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _loss(self, p, y):\n",
    "        return self.dice(p, y) + self.ce(p, y.float())\n",
    "\n",
    "    def forward(self, p, y):\n",
    "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
    "        p_wt, p_tc, p_et = p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1), p[:, 3].unsqueeze(1)\n",
    "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
    "        return l_wt + l_tc + l_et"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693ffff",
   "metadata": {
    "papermill": {
     "duration": 0.005723,
     "end_time": "2025-06-08T09:50:18.014987",
     "exception": false,
     "start_time": "2025-06-08T09:50:18.009264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eae4245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:18.027813Z",
     "iopub.status.busy": "2025-06-08T09:50:18.027470Z",
     "iopub.status.idle": "2025-06-08T09:50:18.034015Z",
     "shell.execute_reply": "2025-06-08T09:50:18.033156Z"
    },
    "papermill": {
     "duration": 0.014988,
     "end_time": "2025-06-08T09:50:18.035670",
     "exception": false,
     "start_time": "2025-06-08T09:50:18.020682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, epoch): # teacher_model, valLoader, epoch\n",
    "    torch.manual_seed(0)\n",
    "    model.eval()\n",
    "    \n",
    "    loss_fn = LossFunction()\n",
    "    n_val_batches = len(loader)\n",
    "    running_loss = 0\n",
    "\n",
    "    with tqdm(total=n_val_batches, desc='Validating', unit='batch', leave=False) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for step, y in enumerate(loader):\n",
    "                y['imgs'], y['masks']= y['imgs'].to('cuda'), y['masks'].to('cuda')\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    output = model(y['imgs']) # No need now for KD!\n",
    "                    val_loss = loss_fn( output['pred'], y['masks'] ) #output['pred'] has 'pred' only due to model.eval() so self.training = False\n",
    "                    print(f\"Validation loss per batch: {val_loss}\")\n",
    "                    \n",
    "                running_loss += val_loss\n",
    "                print(f\"Cumulative loss: {running_loss}\")            \n",
    "                pbar.update(1)\n",
    "    \n",
    "            epoch_loss = running_loss / n_val_batches\n",
    "            print(f\"------Final validation loss after epoch {epoch + 1}: {epoch_loss}-------------\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89d40ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:18.048378Z",
     "iopub.status.busy": "2025-06-08T09:50:18.048133Z",
     "iopub.status.idle": "2025-06-08T09:50:18.062215Z",
     "shell.execute_reply": "2025-06-08T09:50:18.061365Z"
    },
    "papermill": {
     "duration": 0.02262,
     "end_time": "2025-06-08T09:50:18.063910",
     "exception": false,
     "start_time": "2025-06-08T09:50:18.041290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(trainLoader, valLoader, args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    args['out_checkpoint_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    task = Task.init(project_name=\"Fine-tuned model on each dataset\", task_name=f\"Fine-tuned model on each dataset\", reuse_last_task_id=True)\n",
    "    task.connect(args)\n",
    "    task.add_tags(['Fine-tuned model per dataset', \"Ahmed Main\"])\n",
    "\n",
    "    loss_fn = LossFunction()\n",
    "    teacher_model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=True).to(device)\n",
    "    optimizer_teacher = optim.AdamW(teacher_model.parameters(), lr=args['learning_rate'], weight_decay=args['weight_decay'], eps=1e-4)\n",
    "    scaler = amp.GradScaler('cuda')\n",
    "    n_train_batches = len(trainLoader)\n",
    "    scheduler_teacher = optim.lr_scheduler.ReduceLROnPlateau(optimizer_teacher, mode='min', factor=0.1, patience=10, cooldown=1, threshold=0.001, min_lr=1e-6)\n",
    "\n",
    "    teacher_epoch_checkpoint = f'Fine-tuned_model_after_epoch_235_trainLoss_0.8622_valLoss_0.6459.pth'\n",
    "    if (args['in_checkpoint_dir'] / teacher_epoch_checkpoint).is_file():\n",
    "        print(f\"Found model {teacher_epoch_checkpoint}\")\n",
    "        ckpt = torch.load(args['in_checkpoint_dir'] / teacher_epoch_checkpoint, map_location='cuda', weights_only=True)\n",
    "        start_epoch = ckpt['epoch'] + 1 # To start after last saved epoch\n",
    "        teacher_model.load_state_dict(ckpt['teacher_model'])\n",
    "        optimizer_teacher.load_state_dict(ckpt['optimizer_teacher'])\n",
    "        scaler.load_state_dict(ckpt['grad_scaler_state'])\n",
    "        scheduler_teacher.load_state_dict(ckpt['scheduler_state_dict'])\n",
    "        # optimizer_teacher.param_groups[0]['lr'] = args['learning_rate'] # Leave this (overwrite) or remove it as you wish\n",
    "        print(f\"Loaded model {teacher_epoch_checkpoint} with lr: {optimizer_teacher.param_groups[0]['lr']}\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    print(f'''Starting training:\n",
    "            Epochs:          From {start_epoch + 1} to {start_epoch + args['epochs']}\n",
    "            Batch size:      {args['train_batch_size']}\n",
    "            Learning rate:   {optimizer_teacher.param_groups[0]['lr']}\n",
    "            Training data coming from:   {args['data_dir']}\n",
    "    ''')\n",
    "\n",
    "    # Starting training\n",
    "    for epoch in range(start_epoch, start_epoch + args['epochs']):\n",
    "        data_type = None\n",
    "        teacher_model.train()\n",
    "        epoch_loss_teacher = 0\n",
    "        \n",
    "        with tqdm(total=n_train_batches, desc=f\"(Epoch {epoch + 1}/{start_epoch + args['epochs']})\", unit='batch') as pbar:\n",
    "            for step, y in enumerate(trainLoader):\n",
    "                data_type = y['data_type'][0]\n",
    "                y['imgs'], y['masks']= y['imgs'].to(device), y['masks'].to(device)\n",
    "\n",
    "                set_requires_grad(teacher_model, requires_grad=True)\n",
    "                optimizer_teacher.zero_grad()\n",
    "                with amp.autocast('cuda'):  # Mixed precision\n",
    "                    teacher_output = teacher_model(y['imgs'])\n",
    "                    loss_teacher_decoder_1 = loss_fn(teacher_output['pred'][:, 0], y['masks']) # B x 3 x 4 x 128 x 128 x 128\n",
    "                    loss_teacher_decoder_2 = loss_fn(teacher_output['pred'][:, 1], y['masks'])\n",
    "                    loss_teacher_decoder_3 = loss_fn(teacher_output['pred'][:, 2], y['masks'])\n",
    "\n",
    "                    print(f'loss_t_decoder1/batch : {loss_teacher_decoder_1:.4f} || loss_t_decoder2/batch : {loss_teacher_decoder_2:.4f} || loss_t_decoder3/batch : {loss_teacher_decoder_3:.4f}')\n",
    "                    batch_loss_teacher = loss_teacher_decoder_1 + (0.5 * loss_teacher_decoder_2) + (0.25 * loss_teacher_decoder_3)\n",
    "\n",
    "                scaler.scale(batch_loss_teacher).backward()\n",
    "                scaler.step(optimizer_teacher)\n",
    "                scaler.update()\n",
    "\n",
    "                epoch_loss_teacher += batch_loss_teacher.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "            epoch_loss_teacher /= n_train_batches\n",
    "            print(f\"------Final training loss after epoch {epoch + 1}: {epoch_loss_teacher}-------------\")\n",
    "\n",
    "            task.get_logger().report_scalar(f\"Loss on {data_type}\", \"train_loss\", iteration=epoch+1, value=epoch_loss_teacher)\n",
    "            task.get_logger().report_scalar(\"LR\", \"learning_rate\", iteration=epoch+1, value=optimizer_teacher.param_groups[0]['lr'])\n",
    "\n",
    "        # Validation phase\n",
    "        print(f'''\n",
    "            Starting validation:\n",
    "            Epoch:           {epoch + 1}\n",
    "            Batch size:      {args['val_batch_size']}\n",
    "            Validation data coming from: {args['data_dir']}\n",
    "\n",
    "        ''')\n",
    "\n",
    "        val_loss = evaluate(teacher_model, valLoader, epoch)\n",
    "        scheduler_teacher.step(val_loss)\n",
    "        print(f\"Learning rate after epoch {epoch + 1}: {optimizer_teacher.param_groups[0]['lr']}\")\n",
    "        task.get_logger().report_scalar(f\"Loss on {data_type}\", \"val_loss\", iteration=epoch+1, value=val_loss)\n",
    "\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'teacher_model': teacher_model.state_dict(),\n",
    "            'optimizer_teacher': optimizer_teacher.state_dict(),\n",
    "            'lr': optimizer_teacher.param_groups[0]['lr'],\n",
    "            'grad_scaler_state': scaler.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler_teacher.state_dict(),\n",
    "            'val_loss': val_loss\n",
    "        }\n",
    "\n",
    "        torch.save(state, args['out_checkpoint_dir'] / f'Fine-tuned_model_after_epoch_{epoch + 1}_trainLoss_{epoch_loss_teacher:.4f}_valLoss_{val_loss:.4f}.pth')\n",
    "        print(f\"Model saved after epoch {epoch + 1}\")\n",
    "\n",
    "    task.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0478de0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T09:50:18.076233Z",
     "iopub.status.busy": "2025-06-08T09:50:18.075977Z",
     "iopub.status.idle": "2025-06-08T10:57:04.545109Z",
     "shell.execute_reply": "2025-06-08T10:57:04.544244Z"
    },
    "papermill": {
     "duration": 4006.478826,
     "end_time": "2025-06-08T10:57:04.548439",
     "exception": false,
     "start_time": "2025-06-08T09:50:18.069613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 70\n",
      "Number of validation samples 8\n",
      "Number of testing samples 21\n",
      "Using device: cuda\n",
      "ClearML Task: created new task id=c6ee47f01eea4051ab33bf8f6b54a707\n",
      "2025-06-08 09:50:22,731 - clearml.Repository Detection - WARNING - Failed accessing the jupyter server(s): []\n",
      "2025-06-08 09:50:22,769 - clearml.Task - INFO - No repository found, storing script code instead\n",
      "ClearML results page: https://app.clear.ml/projects/970ea00de4564a359d7007ee2d270cca/experiments/c6ee47f01eea4051ab33bf8f6b54a707/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/clearml/utilities/process/mp.py:662: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-08 09:50:26,152 - clearml.Task - WARNING - Parameters must be of builtin type (General/in_checkpoint_dir[PosixPath], General/out_checkpoint_dir[PosixPath])\n",
      "Found model Fine-tuned_model_after_epoch_235_trainLoss_0.8622_valLoss_0.6459.pth\n",
      "Loaded model Fine-tuned_model_after_epoch_235_trainLoss_0.8622_valLoss_0.6459.pth with lr: 0.001\n",
      "Starting training:\n",
      "            Epochs:          From 236 to 265\n",
      "            Batch size:      2\n",
      "            Learning rate:   0.001\n",
      "            Training data coming from:   /kaggle/input/bratsped/Training/\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5411 || loss_t_decoder2/batch : 0.5848 || loss_t_decoder3/batch : 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):   3%|▎         | 1/35 [00:11<06:23, 11.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3410 || loss_t_decoder2/batch : 0.4442 || loss_t_decoder3/batch : 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):   6%|▌         | 2/35 [00:14<03:38,  6.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8192 || loss_t_decoder2/batch : 0.8676 || loss_t_decoder3/batch : 1.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):   9%|▊         | 3/35 [00:18<02:44,  5.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9399 || loss_t_decoder2/batch : 1.0276 || loss_t_decoder3/batch : 1.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  11%|█▏        | 4/35 [00:21<02:17,  4.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4727 || loss_t_decoder2/batch : 0.5648 || loss_t_decoder3/batch : 0.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  14%|█▍        | 5/35 [00:24<02:01,  4.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3018 || loss_t_decoder2/batch : 0.4291 || loss_t_decoder3/batch : 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  17%|█▋        | 6/35 [00:28<01:50,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3217 || loss_t_decoder2/batch : 0.4162 || loss_t_decoder3/batch : 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  20%|██        | 7/35 [00:31<01:42,  3.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4317 || loss_t_decoder2/batch : 0.5253 || loss_t_decoder3/batch : 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  23%|██▎       | 8/35 [00:34<01:36,  3.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2596 || loss_t_decoder2/batch : 0.3194 || loss_t_decoder3/batch : 0.4810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  26%|██▌       | 9/35 [00:38<01:30,  3.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6642 || loss_t_decoder2/batch : 0.7171 || loss_t_decoder3/batch : 0.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  29%|██▊       | 10/35 [00:41<01:26,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4018 || loss_t_decoder2/batch : 0.4639 || loss_t_decoder3/batch : 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  31%|███▏      | 11/35 [00:44<01:22,  3.42s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5403 || loss_t_decoder2/batch : 0.5800 || loss_t_decoder3/batch : 0.6898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  34%|███▍      | 12/35 [00:48<01:18,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7994 || loss_t_decoder2/batch : 0.8889 || loss_t_decoder3/batch : 1.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  37%|███▋      | 13/35 [00:51<01:14,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5315 || loss_t_decoder2/batch : 0.5440 || loss_t_decoder3/batch : 0.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  40%|████      | 14/35 [00:54<01:10,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4849 || loss_t_decoder2/batch : 0.5925 || loss_t_decoder3/batch : 0.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  43%|████▎     | 15/35 [00:58<01:07,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7538 || loss_t_decoder2/batch : 0.8167 || loss_t_decoder3/batch : 0.9503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  46%|████▌     | 16/35 [01:01<01:03,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1602 || loss_t_decoder2/batch : 1.1952 || loss_t_decoder3/batch : 1.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  49%|████▊     | 17/35 [01:04<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3320 || loss_t_decoder2/batch : 0.3913 || loss_t_decoder3/batch : 0.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  51%|█████▏    | 18/35 [01:08<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5947 || loss_t_decoder2/batch : 0.6376 || loss_t_decoder3/batch : 0.8103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  54%|█████▍    | 19/35 [01:11<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6297 || loss_t_decoder2/batch : 0.6355 || loss_t_decoder3/batch : 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  57%|█████▋    | 20/35 [01:15<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2184 || loss_t_decoder2/batch : 0.3093 || loss_t_decoder3/batch : 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  60%|██████    | 21/35 [01:18<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5399 || loss_t_decoder2/batch : 0.5999 || loss_t_decoder3/batch : 0.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  63%|██████▎   | 22/35 [01:21<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5258 || loss_t_decoder2/batch : 0.5794 || loss_t_decoder3/batch : 0.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  66%|██████▌   | 23/35 [01:25<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6550 || loss_t_decoder2/batch : 0.6101 || loss_t_decoder3/batch : 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  69%|██████▊   | 24/35 [01:28<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6606 || loss_t_decoder2/batch : 0.7142 || loss_t_decoder3/batch : 0.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  71%|███████▏  | 25/35 [01:31<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3574 || loss_t_decoder2/batch : 0.4838 || loss_t_decoder3/batch : 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  74%|███████▍  | 26/35 [01:35<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1289 || loss_t_decoder2/batch : 1.1920 || loss_t_decoder3/batch : 1.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  77%|███████▋  | 27/35 [01:38<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8356 || loss_t_decoder2/batch : 0.9032 || loss_t_decoder3/batch : 1.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  80%|████████  | 28/35 [01:41<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3363 || loss_t_decoder2/batch : 0.4336 || loss_t_decoder3/batch : 0.6447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  83%|████████▎ | 29/35 [01:45<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3892 || loss_t_decoder2/batch : 0.5442 || loss_t_decoder3/batch : 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  86%|████████▌ | 30/35 [01:48<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5265 || loss_t_decoder2/batch : 0.6429 || loss_t_decoder3/batch : 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  89%|████████▊ | 31/35 [01:51<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2890 || loss_t_decoder2/batch : 0.3940 || loss_t_decoder3/batch : 0.5897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  91%|█████████▏| 32/35 [01:55<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5818 || loss_t_decoder2/batch : 0.6326 || loss_t_decoder3/batch : 0.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  94%|█████████▍| 33/35 [01:58<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3554 || loss_t_decoder2/batch : 0.4571 || loss_t_decoder3/batch : 0.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265):  97%|█████████▋| 34/35 [02:02<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5515 || loss_t_decoder2/batch : 0.6543 || loss_t_decoder3/batch : 0.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 236/265): 100%|██████████| 35/35 [02:05<00:00,  3.58s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 236: 1.0605663878577096-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           236\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:06<00:19,  6.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6295512318611145\n",
      "Cumulative loss: 0.6295512318611145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:07<00:06,  3.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6407763361930847\n",
      "Cumulative loss: 1.2703275680541992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:12<00:03,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6295137405395508\n",
      "Cumulative loss: 1.89984130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.42621320486068726\n",
      "Cumulative loss: 2.326054573059082\n",
      "------Final validation loss after epoch 236: 0.5815136432647705-------------\n",
      "Learning rate after epoch 236: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3357 || loss_t_decoder2/batch : 0.4102 || loss_t_decoder3/batch : 0.5734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):   3%|▎         | 1/35 [00:05<03:08,  5.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5258 || loss_t_decoder2/batch : 0.6258 || loss_t_decoder3/batch : 0.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):   6%|▌         | 2/35 [00:08<02:20,  4.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2998 || loss_t_decoder2/batch : 0.3868 || loss_t_decoder3/batch : 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):   9%|▊         | 3/35 [00:12<02:03,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5018 || loss_t_decoder2/batch : 0.5798 || loss_t_decoder3/batch : 0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5980 || loss_t_decoder2/batch : 0.6702 || loss_t_decoder3/batch : 0.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5812 || loss_t_decoder2/batch : 0.6443 || loss_t_decoder3/batch : 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2927 || loss_t_decoder2/batch : 0.4200 || loss_t_decoder3/batch : 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3357 || loss_t_decoder2/batch : 0.4357 || loss_t_decoder3/batch : 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  23%|██▎       | 8/35 [00:29<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8171 || loss_t_decoder2/batch : 0.8431 || loss_t_decoder3/batch : 1.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  26%|██▌       | 9/35 [00:32<01:28,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5553 || loss_t_decoder2/batch : 0.6454 || loss_t_decoder3/batch : 0.8497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  29%|██▊       | 10/35 [00:35<01:24,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5167 || loss_t_decoder2/batch : 0.6367 || loss_t_decoder3/batch : 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  31%|███▏      | 11/35 [00:39<01:21,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2709 || loss_t_decoder2/batch : 0.3627 || loss_t_decoder3/batch : 0.5864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2530 || loss_t_decoder2/batch : 0.3276 || loss_t_decoder3/batch : 0.4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  37%|███▋      | 13/35 [00:45<01:14,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4295 || loss_t_decoder2/batch : 0.5511 || loss_t_decoder3/batch : 0.8094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4820 || loss_t_decoder2/batch : 0.5852 || loss_t_decoder3/batch : 0.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3079 || loss_t_decoder2/batch : 0.3924 || loss_t_decoder3/batch : 0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2254 || loss_t_decoder2/batch : 0.3056 || loss_t_decoder3/batch : 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3428 || loss_t_decoder2/batch : 0.4363 || loss_t_decoder3/batch : 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4773 || loss_t_decoder2/batch : 0.5827 || loss_t_decoder3/batch : 0.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7788 || loss_t_decoder2/batch : 0.8187 || loss_t_decoder3/batch : 1.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5422 || loss_t_decoder2/batch : 0.6428 || loss_t_decoder3/batch : 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4568 || loss_t_decoder2/batch : 0.4738 || loss_t_decoder3/batch : 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  63%|██████▎   | 22/35 [01:16<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4868 || loss_t_decoder2/batch : 0.5372 || loss_t_decoder3/batch : 0.6822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3187 || loss_t_decoder2/batch : 0.4343 || loss_t_decoder3/batch : 0.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2829 || loss_t_decoder2/batch : 0.3541 || loss_t_decoder3/batch : 0.5826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3140 || loss_t_decoder2/batch : 0.4669 || loss_t_decoder3/batch : 0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2945 || loss_t_decoder2/batch : 0.4079 || loss_t_decoder3/batch : 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2912 || loss_t_decoder2/batch : 0.3970 || loss_t_decoder3/batch : 0.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4719 || loss_t_decoder2/batch : 0.5519 || loss_t_decoder3/batch : 0.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9352 || loss_t_decoder2/batch : 1.0761 || loss_t_decoder3/batch : 1.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3179 || loss_t_decoder2/batch : 0.4194 || loss_t_decoder3/batch : 0.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2984 || loss_t_decoder2/batch : 0.4272 || loss_t_decoder3/batch : 0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3583 || loss_t_decoder2/batch : 0.4704 || loss_t_decoder3/batch : 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4158 || loss_t_decoder2/batch : 0.4672 || loss_t_decoder3/batch : 0.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1163 || loss_t_decoder2/batch : 1.1606 || loss_t_decoder3/batch : 1.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 237/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 237: 0.9094948615346636-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           237\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6204012632369995\n",
      "Cumulative loss: 0.6204012632369995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.5372094511985779\n",
      "Cumulative loss: 1.1576106548309326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.641930103302002\n",
      "Cumulative loss: 1.7995407581329346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43444663286209106\n",
      "Cumulative loss: 2.233987331390381\n",
      "------Final validation loss after epoch 237: 0.5584968328475952-------------\n",
      "Learning rate after epoch 237: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3067 || loss_t_decoder2/batch : 0.3853 || loss_t_decoder3/batch : 0.5409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):   3%|▎         | 1/35 [00:05<03:03,  5.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5327 || loss_t_decoder2/batch : 0.6388 || loss_t_decoder3/batch : 0.8199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):   6%|▌         | 2/35 [00:08<02:18,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2654 || loss_t_decoder2/batch : 0.3652 || loss_t_decoder3/batch : 0.5977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):   9%|▊         | 3/35 [00:12<02:01,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5094 || loss_t_decoder2/batch : 0.5856 || loss_t_decoder3/batch : 0.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  11%|█▏        | 4/35 [00:15<01:52,  3.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6878 || loss_t_decoder2/batch : 0.7574 || loss_t_decoder3/batch : 0.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4496 || loss_t_decoder2/batch : 0.5028 || loss_t_decoder3/batch : 0.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2770 || loss_t_decoder2/batch : 0.4093 || loss_t_decoder3/batch : 0.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3305 || loss_t_decoder2/batch : 0.4319 || loss_t_decoder3/batch : 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8300 || loss_t_decoder2/batch : 0.8603 || loss_t_decoder3/batch : 1.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5591 || loss_t_decoder2/batch : 0.6332 || loss_t_decoder3/batch : 0.8050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4644 || loss_t_decoder2/batch : 0.5597 || loss_t_decoder3/batch : 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2598 || loss_t_decoder2/batch : 0.3536 || loss_t_decoder3/batch : 0.5682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2223 || loss_t_decoder2/batch : 0.3029 || loss_t_decoder3/batch : 0.4622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4381 || loss_t_decoder2/batch : 0.5518 || loss_t_decoder3/batch : 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4778 || loss_t_decoder2/batch : 0.5766 || loss_t_decoder3/batch : 0.7484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2893 || loss_t_decoder2/batch : 0.3734 || loss_t_decoder3/batch : 0.5731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2188 || loss_t_decoder2/batch : 0.3071 || loss_t_decoder3/batch : 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3338 || loss_t_decoder2/batch : 0.4314 || loss_t_decoder3/batch : 0.6079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4793 || loss_t_decoder2/batch : 0.5859 || loss_t_decoder3/batch : 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6273 || loss_t_decoder2/batch : 0.7199 || loss_t_decoder3/batch : 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5511 || loss_t_decoder2/batch : 0.6623 || loss_t_decoder3/batch : 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3944 || loss_t_decoder2/batch : 0.4200 || loss_t_decoder3/batch : 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4801 || loss_t_decoder2/batch : 0.5292 || loss_t_decoder3/batch : 0.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3185 || loss_t_decoder2/batch : 0.4234 || loss_t_decoder3/batch : 0.6241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2577 || loss_t_decoder2/batch : 0.3442 || loss_t_decoder3/batch : 0.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3130 || loss_t_decoder2/batch : 0.4525 || loss_t_decoder3/batch : 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2886 || loss_t_decoder2/batch : 0.4076 || loss_t_decoder3/batch : 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2951 || loss_t_decoder2/batch : 0.3986 || loss_t_decoder3/batch : 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4741 || loss_t_decoder2/batch : 0.5567 || loss_t_decoder3/batch : 0.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8256 || loss_t_decoder2/batch : 0.9388 || loss_t_decoder3/batch : 1.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3004 || loss_t_decoder2/batch : 0.4042 || loss_t_decoder3/batch : 0.5910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2843 || loss_t_decoder2/batch : 0.4165 || loss_t_decoder3/batch : 0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3400 || loss_t_decoder2/batch : 0.4546 || loss_t_decoder3/batch : 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4026 || loss_t_decoder2/batch : 0.4553 || loss_t_decoder3/batch : 0.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1258 || loss_t_decoder2/batch : 1.1663 || loss_t_decoder3/batch : 1.2756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 238/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 238: 0.8765366920403072-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           238\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.620938777923584\n",
      "Cumulative loss: 0.620938777923584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.5186642408370972\n",
      "Cumulative loss: 1.1396030187606812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6354926228523254\n",
      "Cumulative loss: 1.7750957012176514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4339836835861206\n",
      "Cumulative loss: 2.2090792655944824\n",
      "------Final validation loss after epoch 238: 0.5522698163986206-------------\n",
      "Learning rate after epoch 238: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2939 || loss_t_decoder2/batch : 0.3751 || loss_t_decoder3/batch : 0.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):   3%|▎         | 1/35 [00:05<03:09,  5.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5298 || loss_t_decoder2/batch : 0.6358 || loss_t_decoder3/batch : 0.8176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):   6%|▌         | 2/35 [00:08<02:20,  4.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2623 || loss_t_decoder2/batch : 0.3625 || loss_t_decoder3/batch : 0.5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):   9%|▊         | 3/35 [00:12<02:03,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5109 || loss_t_decoder2/batch : 0.5920 || loss_t_decoder3/batch : 0.7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6578 || loss_t_decoder2/batch : 0.7279 || loss_t_decoder3/batch : 0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  14%|█▍        | 5/35 [00:18<01:46,  3.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4436 || loss_t_decoder2/batch : 0.4973 || loss_t_decoder3/batch : 0.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2621 || loss_t_decoder2/batch : 0.3977 || loss_t_decoder3/batch : 0.6335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3458 || loss_t_decoder2/batch : 0.4411 || loss_t_decoder3/batch : 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  23%|██▎       | 8/35 [00:29<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8275 || loss_t_decoder2/batch : 0.8480 || loss_t_decoder3/batch : 1.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  26%|██▌       | 9/35 [00:32<01:28,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5469 || loss_t_decoder2/batch : 0.6235 || loss_t_decoder3/batch : 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4388 || loss_t_decoder2/batch : 0.5387 || loss_t_decoder3/batch : 0.7484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2547 || loss_t_decoder2/batch : 0.3500 || loss_t_decoder3/batch : 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2236 || loss_t_decoder2/batch : 0.3019 || loss_t_decoder3/batch : 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4343 || loss_t_decoder2/batch : 0.5495 || loss_t_decoder3/batch : 0.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4758 || loss_t_decoder2/batch : 0.5763 || loss_t_decoder3/batch : 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2912 || loss_t_decoder2/batch : 0.3700 || loss_t_decoder3/batch : 0.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2208 || loss_t_decoder2/batch : 0.3041 || loss_t_decoder3/batch : 0.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3363 || loss_t_decoder2/batch : 0.4321 || loss_t_decoder3/batch : 0.6128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4689 || loss_t_decoder2/batch : 0.5765 || loss_t_decoder3/batch : 0.7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6327 || loss_t_decoder2/batch : 0.7154 || loss_t_decoder3/batch : 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5431 || loss_t_decoder2/batch : 0.6539 || loss_t_decoder3/batch : 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3913 || loss_t_decoder2/batch : 0.4151 || loss_t_decoder3/batch : 0.5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  63%|██████▎   | 22/35 [01:16<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4828 || loss_t_decoder2/batch : 0.5332 || loss_t_decoder3/batch : 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3167 || loss_t_decoder2/batch : 0.4250 || loss_t_decoder3/batch : 0.6344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2729 || loss_t_decoder2/batch : 0.3512 || loss_t_decoder3/batch : 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3082 || loss_t_decoder2/batch : 0.4537 || loss_t_decoder3/batch : 0.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2879 || loss_t_decoder2/batch : 0.4057 || loss_t_decoder3/batch : 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2838 || loss_t_decoder2/batch : 0.3913 || loss_t_decoder3/batch : 0.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4679 || loss_t_decoder2/batch : 0.5585 || loss_t_decoder3/batch : 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7466 || loss_t_decoder2/batch : 0.8490 || loss_t_decoder3/batch : 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2957 || loss_t_decoder2/batch : 0.3975 || loss_t_decoder3/batch : 0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3022 || loss_t_decoder2/batch : 0.4205 || loss_t_decoder3/batch : 0.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3282 || loss_t_decoder2/batch : 0.4478 || loss_t_decoder3/batch : 0.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3959 || loss_t_decoder2/batch : 0.4487 || loss_t_decoder3/batch : 0.6169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1212 || loss_t_decoder2/batch : 1.1645 || loss_t_decoder3/batch : 1.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 239/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 239: 0.8664756945201328-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           239\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6195014119148254\n",
      "Cumulative loss: 0.6195014119148254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.5157672166824341\n",
      "Cumulative loss: 1.1352686882019043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6271681785583496\n",
      "Cumulative loss: 1.762436866760254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4330183267593384\n",
      "Cumulative loss: 2.1954550743103027\n",
      "------Final validation loss after epoch 239: 0.5488637685775757-------------\n",
      "Learning rate after epoch 239: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2871 || loss_t_decoder2/batch : 0.3714 || loss_t_decoder3/batch : 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):   3%|▎         | 1/35 [00:05<02:57,  5.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5255 || loss_t_decoder2/batch : 0.6327 || loss_t_decoder3/batch : 0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):   6%|▌         | 2/35 [00:08<02:16,  4.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2685 || loss_t_decoder2/batch : 0.3627 || loss_t_decoder3/batch : 0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):   9%|▊         | 3/35 [00:11<02:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5060 || loss_t_decoder2/batch : 0.5823 || loss_t_decoder3/batch : 0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5447 || loss_t_decoder2/batch : 0.6282 || loss_t_decoder3/batch : 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4771 || loss_t_decoder2/batch : 0.5318 || loss_t_decoder3/batch : 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2877 || loss_t_decoder2/batch : 0.4129 || loss_t_decoder3/batch : 0.6466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3174 || loss_t_decoder2/batch : 0.4222 || loss_t_decoder3/batch : 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8240 || loss_t_decoder2/batch : 0.8521 || loss_t_decoder3/batch : 1.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5443 || loss_t_decoder2/batch : 0.6213 || loss_t_decoder3/batch : 0.8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4300 || loss_t_decoder2/batch : 0.5332 || loss_t_decoder3/batch : 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2508 || loss_t_decoder2/batch : 0.3509 || loss_t_decoder3/batch : 0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2265 || loss_t_decoder2/batch : 0.3089 || loss_t_decoder3/batch : 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4335 || loss_t_decoder2/batch : 0.5476 || loss_t_decoder3/batch : 0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4754 || loss_t_decoder2/batch : 0.5761 || loss_t_decoder3/batch : 0.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2893 || loss_t_decoder2/batch : 0.3680 || loss_t_decoder3/batch : 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2179 || loss_t_decoder2/batch : 0.3001 || loss_t_decoder3/batch : 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3200 || loss_t_decoder2/batch : 0.4199 || loss_t_decoder3/batch : 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5013 || loss_t_decoder2/batch : 0.6049 || loss_t_decoder3/batch : 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5902 || loss_t_decoder2/batch : 0.6922 || loss_t_decoder3/batch : 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5509 || loss_t_decoder2/batch : 0.6521 || loss_t_decoder3/batch : 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3979 || loss_t_decoder2/batch : 0.4230 || loss_t_decoder3/batch : 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4728 || loss_t_decoder2/batch : 0.5234 || loss_t_decoder3/batch : 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3138 || loss_t_decoder2/batch : 0.4159 || loss_t_decoder3/batch : 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2617 || loss_t_decoder2/batch : 0.3454 || loss_t_decoder3/batch : 0.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3089 || loss_t_decoder2/batch : 0.4574 || loss_t_decoder3/batch : 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2870 || loss_t_decoder2/batch : 0.4076 || loss_t_decoder3/batch : 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2900 || loss_t_decoder2/batch : 0.3960 || loss_t_decoder3/batch : 0.5734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4620 || loss_t_decoder2/batch : 0.5517 || loss_t_decoder3/batch : 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7210 || loss_t_decoder2/batch : 0.8281 || loss_t_decoder3/batch : 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2991 || loss_t_decoder2/batch : 0.4046 || loss_t_decoder3/batch : 0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2839 || loss_t_decoder2/batch : 0.4153 || loss_t_decoder3/batch : 0.6895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3259 || loss_t_decoder2/batch : 0.4432 || loss_t_decoder3/batch : 0.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3922 || loss_t_decoder2/batch : 0.4420 || loss_t_decoder3/batch : 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1263 || loss_t_decoder2/batch : 1.1663 || loss_t_decoder3/batch : 1.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 240/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 240: 0.8583393343857356-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           240\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6177384853363037\n",
      "Cumulative loss: 0.6177384853363037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.5116230249404907\n",
      "Cumulative loss: 1.1293615102767944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6245245337486267\n",
      "Cumulative loss: 1.7538859844207764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43369248509407043\n",
      "Cumulative loss: 2.1875784397125244\n",
      "------Final validation loss after epoch 240: 0.5468946099281311-------------\n",
      "Learning rate after epoch 240: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2883 || loss_t_decoder2/batch : 0.3696 || loss_t_decoder3/batch : 0.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):   3%|▎         | 1/35 [00:05<02:57,  5.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5226 || loss_t_decoder2/batch : 0.6311 || loss_t_decoder3/batch : 0.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):   6%|▌         | 2/35 [00:08<02:16,  4.12s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2595 || loss_t_decoder2/batch : 0.3599 || loss_t_decoder3/batch : 0.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):   9%|▊         | 3/35 [00:11<02:00,  3.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5004 || loss_t_decoder2/batch : 0.5833 || loss_t_decoder3/batch : 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6215 || loss_t_decoder2/batch : 0.6996 || loss_t_decoder3/batch : 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4718 || loss_t_decoder2/batch : 0.5283 || loss_t_decoder3/batch : 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2779 || loss_t_decoder2/batch : 0.4086 || loss_t_decoder3/batch : 0.6427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3141 || loss_t_decoder2/batch : 0.4203 || loss_t_decoder3/batch : 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8121 || loss_t_decoder2/batch : 0.8489 || loss_t_decoder3/batch : 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5501 || loss_t_decoder2/batch : 0.6264 || loss_t_decoder3/batch : 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4433 || loss_t_decoder2/batch : 0.5441 || loss_t_decoder3/batch : 0.7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2615 || loss_t_decoder2/batch : 0.3543 || loss_t_decoder3/batch : 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2354 || loss_t_decoder2/batch : 0.3161 || loss_t_decoder3/batch : 0.4602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4355 || loss_t_decoder2/batch : 0.5481 || loss_t_decoder3/batch : 0.7656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4813 || loss_t_decoder2/batch : 0.5830 || loss_t_decoder3/batch : 0.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3024 || loss_t_decoder2/batch : 0.3830 || loss_t_decoder3/batch : 0.5826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2142 || loss_t_decoder2/batch : 0.2974 || loss_t_decoder3/batch : 0.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3167 || loss_t_decoder2/batch : 0.4185 || loss_t_decoder3/batch : 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4602 || loss_t_decoder2/batch : 0.5675 || loss_t_decoder3/batch : 0.7708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5942 || loss_t_decoder2/batch : 0.6939 || loss_t_decoder3/batch : 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5473 || loss_t_decoder2/batch : 0.6483 || loss_t_decoder3/batch : 0.9055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3869 || loss_t_decoder2/batch : 0.4128 || loss_t_decoder3/batch : 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4694 || loss_t_decoder2/batch : 0.5207 || loss_t_decoder3/batch : 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3144 || loss_t_decoder2/batch : 0.4211 || loss_t_decoder3/batch : 0.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2611 || loss_t_decoder2/batch : 0.3448 || loss_t_decoder3/batch : 0.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3102 || loss_t_decoder2/batch : 0.4610 || loss_t_decoder3/batch : 0.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2929 || loss_t_decoder2/batch : 0.4087 || loss_t_decoder3/batch : 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2828 || loss_t_decoder2/batch : 0.3901 || loss_t_decoder3/batch : 0.5710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4578 || loss_t_decoder2/batch : 0.5475 || loss_t_decoder3/batch : 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7191 || loss_t_decoder2/batch : 0.8287 || loss_t_decoder3/batch : 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2967 || loss_t_decoder2/batch : 0.3995 || loss_t_decoder3/batch : 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2908 || loss_t_decoder2/batch : 0.4165 || loss_t_decoder3/batch : 0.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3237 || loss_t_decoder2/batch : 0.4419 || loss_t_decoder3/batch : 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3915 || loss_t_decoder2/batch : 0.4414 || loss_t_decoder3/batch : 0.6179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1265 || loss_t_decoder2/batch : 1.1662 || loss_t_decoder3/batch : 1.2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 241/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 241: 0.8599224644047874-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           241\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:07,  2.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6210086345672607\n",
      "Cumulative loss: 0.6210086345672607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.5017117261886597\n",
      "Cumulative loss: 1.1227203607559204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.32s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6264489889144897\n",
      "Cumulative loss: 1.7491693496704102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4324783384799957\n",
      "Cumulative loss: 2.181647777557373\n",
      "------Final validation loss after epoch 241: 0.5454119443893433-------------\n",
      "Learning rate after epoch 241: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3019 || loss_t_decoder2/batch : 0.3894 || loss_t_decoder3/batch : 0.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):   3%|▎         | 1/35 [00:05<02:59,  5.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5197 || loss_t_decoder2/batch : 0.6268 || loss_t_decoder3/batch : 0.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):   6%|▌         | 2/35 [00:08<02:16,  4.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2735 || loss_t_decoder2/batch : 0.3701 || loss_t_decoder3/batch : 0.5929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):   9%|▊         | 3/35 [00:11<02:01,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4990 || loss_t_decoder2/batch : 0.5811 || loss_t_decoder3/batch : 0.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5300 || loss_t_decoder2/batch : 0.6151 || loss_t_decoder3/batch : 0.8344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4371 || loss_t_decoder2/batch : 0.4931 || loss_t_decoder3/batch : 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2604 || loss_t_decoder2/batch : 0.3939 || loss_t_decoder3/batch : 0.6302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3158 || loss_t_decoder2/batch : 0.4215 || loss_t_decoder3/batch : 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8152 || loss_t_decoder2/batch : 0.8466 || loss_t_decoder3/batch : 1.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5451 || loss_t_decoder2/batch : 0.6257 || loss_t_decoder3/batch : 0.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4396 || loss_t_decoder2/batch : 0.5409 || loss_t_decoder3/batch : 0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2611 || loss_t_decoder2/batch : 0.3535 || loss_t_decoder3/batch : 0.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2190 || loss_t_decoder2/batch : 0.2972 || loss_t_decoder3/batch : 0.4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4299 || loss_t_decoder2/batch : 0.5441 || loss_t_decoder3/batch : 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4814 || loss_t_decoder2/batch : 0.5822 || loss_t_decoder3/batch : 0.7487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2820 || loss_t_decoder2/batch : 0.3630 || loss_t_decoder3/batch : 0.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2127 || loss_t_decoder2/batch : 0.2954 || loss_t_decoder3/batch : 0.5309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3154 || loss_t_decoder2/batch : 0.4154 || loss_t_decoder3/batch : 0.6039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4703 || loss_t_decoder2/batch : 0.5841 || loss_t_decoder3/batch : 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5979 || loss_t_decoder2/batch : 0.6957 || loss_t_decoder3/batch : 0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5388 || loss_t_decoder2/batch : 0.6454 || loss_t_decoder3/batch : 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3785 || loss_t_decoder2/batch : 0.4101 || loss_t_decoder3/batch : 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4760 || loss_t_decoder2/batch : 0.5289 || loss_t_decoder3/batch : 0.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3207 || loss_t_decoder2/batch : 0.4218 || loss_t_decoder3/batch : 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2607 || loss_t_decoder2/batch : 0.3437 || loss_t_decoder3/batch : 0.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3092 || loss_t_decoder2/batch : 0.4594 || loss_t_decoder3/batch : 0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2899 || loss_t_decoder2/batch : 0.4068 || loss_t_decoder3/batch : 0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2878 || loss_t_decoder2/batch : 0.3939 || loss_t_decoder3/batch : 0.5712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4318 || loss_t_decoder2/batch : 0.5213 || loss_t_decoder3/batch : 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6930 || loss_t_decoder2/batch : 0.8028 || loss_t_decoder3/batch : 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2969 || loss_t_decoder2/batch : 0.4033 || loss_t_decoder3/batch : 0.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2859 || loss_t_decoder2/batch : 0.4154 || loss_t_decoder3/batch : 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3251 || loss_t_decoder2/batch : 0.4431 || loss_t_decoder3/batch : 0.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3856 || loss_t_decoder2/batch : 0.4373 || loss_t_decoder3/batch : 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1246 || loss_t_decoder2/batch : 1.1650 || loss_t_decoder3/batch : 1.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 242/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 242: 0.8493613140923636-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           242\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6221919059753418\n",
      "Cumulative loss: 0.6221919059753418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4948664903640747\n",
      "Cumulative loss: 1.1170583963394165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6270021796226501\n",
      "Cumulative loss: 1.7440605163574219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43295663595199585\n",
      "Cumulative loss: 2.1770172119140625\n",
      "------Final validation loss after epoch 242: 0.5442543029785156-------------\n",
      "Learning rate after epoch 242: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3035 || loss_t_decoder2/batch : 0.3875 || loss_t_decoder3/batch : 0.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):   3%|▎         | 1/35 [00:05<02:58,  5.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5164 || loss_t_decoder2/batch : 0.6275 || loss_t_decoder3/batch : 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):   6%|▌         | 2/35 [00:08<02:16,  4.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2641 || loss_t_decoder2/batch : 0.3638 || loss_t_decoder3/batch : 0.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):   9%|▊         | 3/35 [00:11<02:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5060 || loss_t_decoder2/batch : 0.5806 || loss_t_decoder3/batch : 0.7482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6110 || loss_t_decoder2/batch : 0.6879 || loss_t_decoder3/batch : 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4653 || loss_t_decoder2/batch : 0.5232 || loss_t_decoder3/batch : 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2590 || loss_t_decoder2/batch : 0.3949 || loss_t_decoder3/batch : 0.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3276 || loss_t_decoder2/batch : 0.4273 || loss_t_decoder3/batch : 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8066 || loss_t_decoder2/batch : 0.8452 || loss_t_decoder3/batch : 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5455 || loss_t_decoder2/batch : 0.6214 || loss_t_decoder3/batch : 0.7974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4240 || loss_t_decoder2/batch : 0.5289 || loss_t_decoder3/batch : 0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2587 || loss_t_decoder2/batch : 0.3522 || loss_t_decoder3/batch : 0.5617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2180 || loss_t_decoder2/batch : 0.2983 || loss_t_decoder3/batch : 0.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4362 || loss_t_decoder2/batch : 0.5491 || loss_t_decoder3/batch : 0.7663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4751 || loss_t_decoder2/batch : 0.5740 || loss_t_decoder3/batch : 0.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2853 || loss_t_decoder2/batch : 0.3637 || loss_t_decoder3/batch : 0.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2137 || loss_t_decoder2/batch : 0.2962 || loss_t_decoder3/batch : 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3142 || loss_t_decoder2/batch : 0.4142 || loss_t_decoder3/batch : 0.6034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4557 || loss_t_decoder2/batch : 0.5618 || loss_t_decoder3/batch : 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5928 || loss_t_decoder2/batch : 0.6945 || loss_t_decoder3/batch : 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5417 || loss_t_decoder2/batch : 0.6413 || loss_t_decoder3/batch : 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3772 || loss_t_decoder2/batch : 0.4078 || loss_t_decoder3/batch : 0.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4782 || loss_t_decoder2/batch : 0.5283 || loss_t_decoder3/batch : 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3192 || loss_t_decoder2/batch : 0.4217 || loss_t_decoder3/batch : 0.6432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2617 || loss_t_decoder2/batch : 0.3469 || loss_t_decoder3/batch : 0.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3089 || loss_t_decoder2/batch : 0.4584 || loss_t_decoder3/batch : 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2999 || loss_t_decoder2/batch : 0.4180 || loss_t_decoder3/batch : 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2776 || loss_t_decoder2/batch : 0.3876 || loss_t_decoder3/batch : 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4550 || loss_t_decoder2/batch : 0.5327 || loss_t_decoder3/batch : 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6872 || loss_t_decoder2/batch : 0.7987 || loss_t_decoder3/batch : 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2975 || loss_t_decoder2/batch : 0.3899 || loss_t_decoder3/batch : 0.5807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2887 || loss_t_decoder2/batch : 0.4158 || loss_t_decoder3/batch : 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3152 || loss_t_decoder2/batch : 0.4330 || loss_t_decoder3/batch : 0.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3860 || loss_t_decoder2/batch : 0.4414 || loss_t_decoder3/batch : 0.6256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1231 || loss_t_decoder2/batch : 1.1652 || loss_t_decoder3/batch : 1.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 243/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 243: 0.8526065051555634-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           243\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:07,  2.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6204715371131897\n",
      "Cumulative loss: 0.6204715371131897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4938163161277771\n",
      "Cumulative loss: 1.1142878532409668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6290466785430908\n",
      "Cumulative loss: 1.7433345317840576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43243011832237244\n",
      "Cumulative loss: 2.175764560699463\n",
      "------Final validation loss after epoch 243: 0.5439411401748657-------------\n",
      "Learning rate after epoch 243: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2782 || loss_t_decoder2/batch : 0.3606 || loss_t_decoder3/batch : 0.5342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):   3%|▎         | 1/35 [00:05<03:02,  5.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5209 || loss_t_decoder2/batch : 0.6278 || loss_t_decoder3/batch : 0.8136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):   6%|▌         | 2/35 [00:08<02:18,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2550 || loss_t_decoder2/batch : 0.3563 || loss_t_decoder3/batch : 0.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):   9%|▊         | 3/35 [00:12<02:01,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4964 || loss_t_decoder2/batch : 0.5778 || loss_t_decoder3/batch : 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  11%|█▏        | 4/35 [00:15<01:52,  3.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5213 || loss_t_decoder2/batch : 0.6094 || loss_t_decoder3/batch : 0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4625 || loss_t_decoder2/batch : 0.5207 || loss_t_decoder3/batch : 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2763 || loss_t_decoder2/batch : 0.4042 || loss_t_decoder3/batch : 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3142 || loss_t_decoder2/batch : 0.4194 || loss_t_decoder3/batch : 0.6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8151 || loss_t_decoder2/batch : 0.8493 || loss_t_decoder3/batch : 1.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5431 || loss_t_decoder2/batch : 0.6209 || loss_t_decoder3/batch : 0.7958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4252 || loss_t_decoder2/batch : 0.5307 || loss_t_decoder3/batch : 0.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2562 || loss_t_decoder2/batch : 0.3532 || loss_t_decoder3/batch : 0.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2193 || loss_t_decoder2/batch : 0.3013 || loss_t_decoder3/batch : 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4256 || loss_t_decoder2/batch : 0.5397 || loss_t_decoder3/batch : 0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4802 || loss_t_decoder2/batch : 0.5815 || loss_t_decoder3/batch : 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2817 || loss_t_decoder2/batch : 0.3670 || loss_t_decoder3/batch : 0.5660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2127 || loss_t_decoder2/batch : 0.2929 || loss_t_decoder3/batch : 0.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3120 || loss_t_decoder2/batch : 0.4124 || loss_t_decoder3/batch : 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4499 || loss_t_decoder2/batch : 0.5608 || loss_t_decoder3/batch : 0.7588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5893 || loss_t_decoder2/batch : 0.6922 || loss_t_decoder3/batch : 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5397 || loss_t_decoder2/batch : 0.6378 || loss_t_decoder3/batch : 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3767 || loss_t_decoder2/batch : 0.4080 || loss_t_decoder3/batch : 0.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4646 || loss_t_decoder2/batch : 0.5164 || loss_t_decoder3/batch : 0.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3140 || loss_t_decoder2/batch : 0.4153 || loss_t_decoder3/batch : 0.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2581 || loss_t_decoder2/batch : 0.3434 || loss_t_decoder3/batch : 0.5534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3078 || loss_t_decoder2/batch : 0.4563 || loss_t_decoder3/batch : 0.7070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3014 || loss_t_decoder2/batch : 0.4213 || loss_t_decoder3/batch : 0.6776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2811 || loss_t_decoder2/batch : 0.3897 || loss_t_decoder3/batch : 0.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4229 || loss_t_decoder2/batch : 0.5138 || loss_t_decoder3/batch : 0.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6913 || loss_t_decoder2/batch : 0.8065 || loss_t_decoder3/batch : 0.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2924 || loss_t_decoder2/batch : 0.4016 || loss_t_decoder3/batch : 0.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2846 || loss_t_decoder2/batch : 0.4144 || loss_t_decoder3/batch : 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3204 || loss_t_decoder2/batch : 0.4398 || loss_t_decoder3/batch : 0.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3828 || loss_t_decoder2/batch : 0.4348 || loss_t_decoder3/batch : 0.6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1267 || loss_t_decoder2/batch : 1.1647 || loss_t_decoder3/batch : 1.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 244/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 244: 0.8444689103535243-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           244\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6201727986335754\n",
      "Cumulative loss: 0.6201727986335754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.49228546023368835\n",
      "Cumulative loss: 1.1124582290649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6248421669006348\n",
      "Cumulative loss: 1.7373003959655762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4323637783527374\n",
      "Cumulative loss: 2.169664144515991\n",
      "------Final validation loss after epoch 244: 0.5424160361289978-------------\n",
      "Learning rate after epoch 244: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3215 || loss_t_decoder2/batch : 0.4054 || loss_t_decoder3/batch : 0.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):   3%|▎         | 1/35 [00:05<03:08,  5.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5144 || loss_t_decoder2/batch : 0.6232 || loss_t_decoder3/batch : 0.8116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):   6%|▌         | 2/35 [00:08<02:20,  4.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2616 || loss_t_decoder2/batch : 0.3574 || loss_t_decoder3/batch : 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):   9%|▊         | 3/35 [00:12<02:02,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5005 || loss_t_decoder2/batch : 0.5761 || loss_t_decoder3/batch : 0.7439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5984 || loss_t_decoder2/batch : 0.6735 || loss_t_decoder3/batch : 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4308 || loss_t_decoder2/batch : 0.4898 || loss_t_decoder3/batch : 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2752 || loss_t_decoder2/batch : 0.4038 || loss_t_decoder3/batch : 0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3096 || loss_t_decoder2/batch : 0.4175 || loss_t_decoder3/batch : 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  23%|██▎       | 8/35 [00:29<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7979 || loss_t_decoder2/batch : 0.8373 || loss_t_decoder3/batch : 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5395 || loss_t_decoder2/batch : 0.6168 || loss_t_decoder3/batch : 0.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4362 || loss_t_decoder2/batch : 0.5386 || loss_t_decoder3/batch : 0.7496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2420 || loss_t_decoder2/batch : 0.3452 || loss_t_decoder3/batch : 0.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2215 || loss_t_decoder2/batch : 0.3049 || loss_t_decoder3/batch : 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4253 || loss_t_decoder2/batch : 0.5393 || loss_t_decoder3/batch : 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4741 || loss_t_decoder2/batch : 0.5737 || loss_t_decoder3/batch : 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2850 || loss_t_decoder2/batch : 0.3678 || loss_t_decoder3/batch : 0.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2107 || loss_t_decoder2/batch : 0.2917 || loss_t_decoder3/batch : 0.5256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3126 || loss_t_decoder2/batch : 0.4124 || loss_t_decoder3/batch : 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4674 || loss_t_decoder2/batch : 0.5732 || loss_t_decoder3/batch : 0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5885 || loss_t_decoder2/batch : 0.6913 || loss_t_decoder3/batch : 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5359 || loss_t_decoder2/batch : 0.6331 || loss_t_decoder3/batch : 0.8924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3732 || loss_t_decoder2/batch : 0.4101 || loss_t_decoder3/batch : 0.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4709 || loss_t_decoder2/batch : 0.5237 || loss_t_decoder3/batch : 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3122 || loss_t_decoder2/batch : 0.4136 || loss_t_decoder3/batch : 0.6344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2616 || loss_t_decoder2/batch : 0.3438 || loss_t_decoder3/batch : 0.5553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3062 || loss_t_decoder2/batch : 0.4548 || loss_t_decoder3/batch : 0.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2910 || loss_t_decoder2/batch : 0.4083 || loss_t_decoder3/batch : 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2804 || loss_t_decoder2/batch : 0.3880 || loss_t_decoder3/batch : 0.5703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  80%|████████  | 28/35 [01:36<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4374 || loss_t_decoder2/batch : 0.5314 || loss_t_decoder3/batch : 0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6853 || loss_t_decoder2/batch : 0.8029 || loss_t_decoder3/batch : 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2870 || loss_t_decoder2/batch : 0.3946 || loss_t_decoder3/batch : 0.5825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2839 || loss_t_decoder2/batch : 0.4135 || loss_t_decoder3/batch : 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3167 || loss_t_decoder2/batch : 0.4350 || loss_t_decoder3/batch : 0.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3808 || loss_t_decoder2/batch : 0.4330 || loss_t_decoder3/batch : 0.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1247 || loss_t_decoder2/batch : 1.1645 || loss_t_decoder3/batch : 1.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 245/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 245: 0.8471814257758005-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           245\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6224671006202698\n",
      "Cumulative loss: 0.6224671006202698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.49110084772109985\n",
      "Cumulative loss: 1.1135679483413696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6301267743110657\n",
      "Cumulative loss: 1.74369478225708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4335997402667999\n",
      "Cumulative loss: 2.1772944927215576\n",
      "------Final validation loss after epoch 245: 0.5443236231803894-------------\n",
      "Learning rate after epoch 245: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3214 || loss_t_decoder2/batch : 0.4042 || loss_t_decoder3/batch : 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):   3%|▎         | 1/35 [00:05<03:16,  5.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5130 || loss_t_decoder2/batch : 0.6225 || loss_t_decoder3/batch : 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):   6%|▌         | 2/35 [00:09<02:23,  4.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2599 || loss_t_decoder2/batch : 0.3567 || loss_t_decoder3/batch : 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):   9%|▊         | 3/35 [00:12<02:04,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5095 || loss_t_decoder2/batch : 0.5840 || loss_t_decoder3/batch : 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  11%|█▏        | 4/35 [00:15<01:54,  3.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5917 || loss_t_decoder2/batch : 0.6694 || loss_t_decoder3/batch : 0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  14%|█▍        | 5/35 [00:19<01:46,  3.56s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4585 || loss_t_decoder2/batch : 0.5183 || loss_t_decoder3/batch : 0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  17%|█▋        | 6/35 [00:22<01:41,  3.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2741 || loss_t_decoder2/batch : 0.4051 || loss_t_decoder3/batch : 0.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  20%|██        | 7/35 [00:25<01:36,  3.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3108 || loss_t_decoder2/batch : 0.4179 || loss_t_decoder3/batch : 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  23%|██▎       | 8/35 [00:29<01:32,  3.42s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7980 || loss_t_decoder2/batch : 0.8373 || loss_t_decoder3/batch : 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  26%|██▌       | 9/35 [00:32<01:28,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5418 || loss_t_decoder2/batch : 0.6189 || loss_t_decoder3/batch : 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  29%|██▊       | 10/35 [00:35<01:24,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4460 || loss_t_decoder2/batch : 0.5474 || loss_t_decoder3/batch : 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  31%|███▏      | 11/35 [00:39<01:21,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2549 || loss_t_decoder2/batch : 0.3522 || loss_t_decoder3/batch : 0.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2171 || loss_t_decoder2/batch : 0.2989 || loss_t_decoder3/batch : 0.4606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  37%|███▋      | 13/35 [00:46<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4362 || loss_t_decoder2/batch : 0.5562 || loss_t_decoder3/batch : 0.7788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4813 || loss_t_decoder2/batch : 0.5810 || loss_t_decoder3/batch : 0.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2856 || loss_t_decoder2/batch : 0.3644 || loss_t_decoder3/batch : 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  46%|████▌     | 16/35 [00:56<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2102 || loss_t_decoder2/batch : 0.2921 || loss_t_decoder3/batch : 0.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3128 || loss_t_decoder2/batch : 0.4109 || loss_t_decoder3/batch : 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4466 || loss_t_decoder2/batch : 0.5560 || loss_t_decoder3/batch : 0.7546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  54%|█████▍    | 19/35 [01:06<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5812 || loss_t_decoder2/batch : 0.6878 || loss_t_decoder3/batch : 0.9235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5365 || loss_t_decoder2/batch : 0.6318 || loss_t_decoder3/batch : 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3712 || loss_t_decoder2/batch : 0.4060 || loss_t_decoder3/batch : 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  63%|██████▎   | 22/35 [01:16<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4618 || loss_t_decoder2/batch : 0.5131 || loss_t_decoder3/batch : 0.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3110 || loss_t_decoder2/batch : 0.4124 || loss_t_decoder3/batch : 0.6345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2627 || loss_t_decoder2/batch : 0.3458 || loss_t_decoder3/batch : 0.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3026 || loss_t_decoder2/batch : 0.4467 || loss_t_decoder3/batch : 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2905 || loss_t_decoder2/batch : 0.4080 || loss_t_decoder3/batch : 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  77%|███████▋  | 27/35 [01:33<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2808 || loss_t_decoder2/batch : 0.3882 || loss_t_decoder3/batch : 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4152 || loss_t_decoder2/batch : 0.5083 || loss_t_decoder3/batch : 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6709 || loss_t_decoder2/batch : 0.7863 || loss_t_decoder3/batch : 0.9482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  86%|████████▌ | 30/35 [01:43<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2910 || loss_t_decoder2/batch : 0.4010 || loss_t_decoder3/batch : 0.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2816 || loss_t_decoder2/batch : 0.4133 || loss_t_decoder3/batch : 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3146 || loss_t_decoder2/batch : 0.4317 || loss_t_decoder3/batch : 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  94%|█████████▍| 33/35 [01:53<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3818 || loss_t_decoder2/batch : 0.4363 || loss_t_decoder3/batch : 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1252 || loss_t_decoder2/batch : 1.1647 || loss_t_decoder3/batch : 1.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 246/265): 100%|██████████| 35/35 [01:59<00:00,  3.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 246: 0.8466283661978585-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           246\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6204349994659424\n",
      "Cumulative loss: 0.6204349994659424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4923648238182068\n",
      "Cumulative loss: 1.112799882888794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.33s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6256987452507019\n",
      "Cumulative loss: 1.7384986877441406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4327913224697113\n",
      "Cumulative loss: 2.1712899208068848\n",
      "------Final validation loss after epoch 246: 0.5428224802017212-------------\n",
      "Learning rate after epoch 246: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2895 || loss_t_decoder2/batch : 0.3757 || loss_t_decoder3/batch : 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):   3%|▎         | 1/35 [00:05<03:01,  5.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5116 || loss_t_decoder2/batch : 0.6215 || loss_t_decoder3/batch : 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):   6%|▌         | 2/35 [00:08<02:17,  4.17s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2540 || loss_t_decoder2/batch : 0.3553 || loss_t_decoder3/batch : 0.5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):   9%|▊         | 3/35 [00:12<02:01,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4929 || loss_t_decoder2/batch : 0.5749 || loss_t_decoder3/batch : 0.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5838 || loss_t_decoder2/batch : 0.6592 || loss_t_decoder3/batch : 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4553 || loss_t_decoder2/batch : 0.5156 || loss_t_decoder3/batch : 0.6972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2748 || loss_t_decoder2/batch : 0.4029 || loss_t_decoder3/batch : 0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3096 || loss_t_decoder2/batch : 0.4172 || loss_t_decoder3/batch : 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8100 || loss_t_decoder2/batch : 0.8442 || loss_t_decoder3/batch : 1.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5388 || loss_t_decoder2/batch : 0.6145 || loss_t_decoder3/batch : 0.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4342 || loss_t_decoder2/batch : 0.5368 || loss_t_decoder3/batch : 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2559 || loss_t_decoder2/batch : 0.3525 || loss_t_decoder3/batch : 0.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2162 || loss_t_decoder2/batch : 0.3024 || loss_t_decoder3/batch : 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4200 || loss_t_decoder2/batch : 0.5290 || loss_t_decoder3/batch : 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4797 || loss_t_decoder2/batch : 0.5803 || loss_t_decoder3/batch : 0.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2826 || loss_t_decoder2/batch : 0.3655 || loss_t_decoder3/batch : 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2096 || loss_t_decoder2/batch : 0.2902 || loss_t_decoder3/batch : 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3105 || loss_t_decoder2/batch : 0.4096 || loss_t_decoder3/batch : 0.6038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4650 || loss_t_decoder2/batch : 0.5704 || loss_t_decoder3/batch : 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5882 || loss_t_decoder2/batch : 0.6901 || loss_t_decoder3/batch : 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5322 || loss_t_decoder2/batch : 0.6351 || loss_t_decoder3/batch : 0.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3683 || loss_t_decoder2/batch : 0.4063 || loss_t_decoder3/batch : 0.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4600 || loss_t_decoder2/batch : 0.5127 || loss_t_decoder3/batch : 0.6597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3113 || loss_t_decoder2/batch : 0.4123 || loss_t_decoder3/batch : 0.6340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2675 || loss_t_decoder2/batch : 0.3461 || loss_t_decoder3/batch : 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3016 || loss_t_decoder2/batch : 0.4415 || loss_t_decoder3/batch : 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3021 || loss_t_decoder2/batch : 0.4190 || loss_t_decoder3/batch : 0.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2786 || loss_t_decoder2/batch : 0.3869 || loss_t_decoder3/batch : 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4148 || loss_t_decoder2/batch : 0.5065 || loss_t_decoder3/batch : 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6789 || loss_t_decoder2/batch : 0.7981 || loss_t_decoder3/batch : 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2827 || loss_t_decoder2/batch : 0.3924 || loss_t_decoder3/batch : 0.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2854 || loss_t_decoder2/batch : 0.4149 || loss_t_decoder3/batch : 0.6823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3146 || loss_t_decoder2/batch : 0.4320 || loss_t_decoder3/batch : 0.6273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3805 || loss_t_decoder2/batch : 0.4350 || loss_t_decoder3/batch : 0.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1251 || loss_t_decoder2/batch : 1.1645 || loss_t_decoder3/batch : 1.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 247/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 247: 0.843718148129327-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           247\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:07,  2.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6231560707092285\n",
      "Cumulative loss: 0.6231560707092285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.48639655113220215\n",
      "Cumulative loss: 1.1095526218414307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6264078617095947\n",
      "Cumulative loss: 1.7359604835510254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43221044540405273\n",
      "Cumulative loss: 2.168170928955078\n",
      "------Final validation loss after epoch 247: 0.5420427322387695-------------\n",
      "Learning rate after epoch 247: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2944 || loss_t_decoder2/batch : 0.3771 || loss_t_decoder3/batch : 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):   3%|▎         | 1/35 [00:05<02:59,  5.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5154 || loss_t_decoder2/batch : 0.6300 || loss_t_decoder3/batch : 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):   6%|▌         | 2/35 [00:08<02:17,  4.17s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2592 || loss_t_decoder2/batch : 0.3559 || loss_t_decoder3/batch : 0.5869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):   9%|▊         | 3/35 [00:12<02:01,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4964 || loss_t_decoder2/batch : 0.5721 || loss_t_decoder3/batch : 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5133 || loss_t_decoder2/batch : 0.5968 || loss_t_decoder3/batch : 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4261 || loss_t_decoder2/batch : 0.4862 || loss_t_decoder3/batch : 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2570 || loss_t_decoder2/batch : 0.3910 || loss_t_decoder3/batch : 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3096 || loss_t_decoder2/batch : 0.4170 || loss_t_decoder3/batch : 0.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8041 || loss_t_decoder2/batch : 0.8392 || loss_t_decoder3/batch : 1.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5382 || loss_t_decoder2/batch : 0.6150 || loss_t_decoder3/batch : 0.8015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4208 || loss_t_decoder2/batch : 0.5270 || loss_t_decoder3/batch : 0.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2419 || loss_t_decoder2/batch : 0.3437 || loss_t_decoder3/batch : 0.5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2173 || loss_t_decoder2/batch : 0.3020 || loss_t_decoder3/batch : 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4207 || loss_t_decoder2/batch : 0.5304 || loss_t_decoder3/batch : 0.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4738 || loss_t_decoder2/batch : 0.5722 || loss_t_decoder3/batch : 0.7408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2789 || loss_t_decoder2/batch : 0.3644 || loss_t_decoder3/batch : 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2076 || loss_t_decoder2/batch : 0.2894 || loss_t_decoder3/batch : 0.5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3113 || loss_t_decoder2/batch : 0.4097 || loss_t_decoder3/batch : 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4578 || loss_t_decoder2/batch : 0.5688 || loss_t_decoder3/batch : 0.7708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5802 || loss_t_decoder2/batch : 0.6862 || loss_t_decoder3/batch : 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5292 || loss_t_decoder2/batch : 0.6321 || loss_t_decoder3/batch : 0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3680 || loss_t_decoder2/batch : 0.4037 || loss_t_decoder3/batch : 0.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4595 || loss_t_decoder2/batch : 0.5116 || loss_t_decoder3/batch : 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3124 || loss_t_decoder2/batch : 0.4114 || loss_t_decoder3/batch : 0.6371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2637 || loss_t_decoder2/batch : 0.3441 || loss_t_decoder3/batch : 0.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3054 || loss_t_decoder2/batch : 0.4530 || loss_t_decoder3/batch : 0.7048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2994 || loss_t_decoder2/batch : 0.4175 || loss_t_decoder3/batch : 0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2872 || loss_t_decoder2/batch : 0.3923 || loss_t_decoder3/batch : 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4239 || loss_t_decoder2/batch : 0.5226 || loss_t_decoder3/batch : 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6803 || loss_t_decoder2/batch : 0.7974 || loss_t_decoder3/batch : 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2992 || loss_t_decoder2/batch : 0.4115 || loss_t_decoder3/batch : 0.6024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2813 || loss_t_decoder2/batch : 0.4128 || loss_t_decoder3/batch : 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3121 || loss_t_decoder2/batch : 0.4327 || loss_t_decoder3/batch : 0.6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3775 || loss_t_decoder2/batch : 0.4313 || loss_t_decoder3/batch : 0.6135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1262 || loss_t_decoder2/batch : 1.1640 || loss_t_decoder3/batch : 1.2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 248/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 248: 0.8378167612212045-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           248\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6237291097640991\n",
      "Cumulative loss: 0.6237291097640991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.48648539185523987\n",
      "Cumulative loss: 1.1102144718170166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6242228746414185\n",
      "Cumulative loss: 1.734437346458435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43363362550735474\n",
      "Cumulative loss: 2.1680710315704346\n",
      "------Final validation loss after epoch 248: 0.5420177578926086-------------\n",
      "Learning rate after epoch 248: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2760 || loss_t_decoder2/batch : 0.3617 || loss_t_decoder3/batch : 0.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):   3%|▎         | 1/35 [00:05<02:58,  5.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5148 || loss_t_decoder2/batch : 0.6245 || loss_t_decoder3/batch : 0.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):   6%|▌         | 2/35 [00:08<02:16,  4.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2527 || loss_t_decoder2/batch : 0.3549 || loss_t_decoder3/batch : 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):   9%|▊         | 3/35 [00:11<02:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4948 || loss_t_decoder2/batch : 0.5703 || loss_t_decoder3/batch : 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5807 || loss_t_decoder2/batch : 0.6565 || loss_t_decoder3/batch : 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4540 || loss_t_decoder2/batch : 0.5151 || loss_t_decoder3/batch : 0.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2752 || loss_t_decoder2/batch : 0.4047 || loss_t_decoder3/batch : 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3083 || loss_t_decoder2/batch : 0.4171 || loss_t_decoder3/batch : 0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8023 || loss_t_decoder2/batch : 0.8380 || loss_t_decoder3/batch : 1.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5358 || loss_t_decoder2/batch : 0.6121 || loss_t_decoder3/batch : 0.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4314 || loss_t_decoder2/batch : 0.5343 || loss_t_decoder3/batch : 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2407 || loss_t_decoder2/batch : 0.3431 || loss_t_decoder3/batch : 0.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2142 || loss_t_decoder2/batch : 0.2973 || loss_t_decoder3/batch : 0.4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4198 || loss_t_decoder2/batch : 0.5289 || loss_t_decoder3/batch : 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4743 || loss_t_decoder2/batch : 0.5713 || loss_t_decoder3/batch : 0.7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2815 || loss_t_decoder2/batch : 0.3603 || loss_t_decoder3/batch : 0.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2067 || loss_t_decoder2/batch : 0.2888 || loss_t_decoder3/batch : 0.5182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3182 || loss_t_decoder2/batch : 0.4157 || loss_t_decoder3/batch : 0.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4593 || loss_t_decoder2/batch : 0.5646 || loss_t_decoder3/batch : 0.7683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5889 || loss_t_decoder2/batch : 0.6882 || loss_t_decoder3/batch : 0.9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5262 || loss_t_decoder2/batch : 0.6295 || loss_t_decoder3/batch : 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3656 || loss_t_decoder2/batch : 0.4038 || loss_t_decoder3/batch : 0.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4662 || loss_t_decoder2/batch : 0.5192 || loss_t_decoder3/batch : 0.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3089 || loss_t_decoder2/batch : 0.4102 || loss_t_decoder3/batch : 0.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2635 || loss_t_decoder2/batch : 0.3453 || loss_t_decoder3/batch : 0.5618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3042 || loss_t_decoder2/batch : 0.4481 || loss_t_decoder3/batch : 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3004 || loss_t_decoder2/batch : 0.4179 || loss_t_decoder3/batch : 0.6739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2798 || loss_t_decoder2/batch : 0.3874 || loss_t_decoder3/batch : 0.5671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4133 || loss_t_decoder2/batch : 0.5059 || loss_t_decoder3/batch : 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6776 || loss_t_decoder2/batch : 0.7994 || loss_t_decoder3/batch : 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2842 || loss_t_decoder2/batch : 0.3963 || loss_t_decoder3/batch : 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2792 || loss_t_decoder2/batch : 0.4121 || loss_t_decoder3/batch : 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3137 || loss_t_decoder2/batch : 0.4342 || loss_t_decoder3/batch : 0.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3768 || loss_t_decoder2/batch : 0.4336 || loss_t_decoder3/batch : 0.6097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1259 || loss_t_decoder2/batch : 1.1639 || loss_t_decoder3/batch : 1.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 249/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 249: 0.840725896188191-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           249\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6233267784118652\n",
      "Cumulative loss: 0.6233267784118652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4870566427707672\n",
      "Cumulative loss: 1.11038339138031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6218174695968628\n",
      "Cumulative loss: 1.7322008609771729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4340684413909912\n",
      "Cumulative loss: 2.166269302368164\n",
      "------Final validation loss after epoch 249: 0.541567325592041-------------\n",
      "Learning rate after epoch 249: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2980 || loss_t_decoder2/batch : 0.3765 || loss_t_decoder3/batch : 0.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):   3%|▎         | 1/35 [00:05<03:03,  5.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5123 || loss_t_decoder2/batch : 0.6227 || loss_t_decoder3/batch : 0.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):   6%|▌         | 2/35 [00:08<02:18,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2543 || loss_t_decoder2/batch : 0.3580 || loss_t_decoder3/batch : 0.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):   9%|▊         | 3/35 [00:12<02:01,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4936 || loss_t_decoder2/batch : 0.5695 || loss_t_decoder3/batch : 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  11%|█▏        | 4/35 [00:15<01:52,  3.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5790 || loss_t_decoder2/batch : 0.6572 || loss_t_decoder3/batch : 0.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4503 || loss_t_decoder2/batch : 0.5131 || loss_t_decoder3/batch : 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2671 || loss_t_decoder2/batch : 0.4027 || loss_t_decoder3/batch : 0.6396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3089 || loss_t_decoder2/batch : 0.4169 || loss_t_decoder3/batch : 0.6505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7949 || loss_t_decoder2/batch : 0.8350 || loss_t_decoder3/batch : 0.9874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5401 || loss_t_decoder2/batch : 0.6186 || loss_t_decoder3/batch : 0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4332 || loss_t_decoder2/batch : 0.5341 || loss_t_decoder3/batch : 0.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2405 || loss_t_decoder2/batch : 0.3444 || loss_t_decoder3/batch : 0.5633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2184 || loss_t_decoder2/batch : 0.3025 || loss_t_decoder3/batch : 0.4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4189 || loss_t_decoder2/batch : 0.5282 || loss_t_decoder3/batch : 0.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4806 || loss_t_decoder2/batch : 0.5796 || loss_t_decoder3/batch : 0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2776 || loss_t_decoder2/batch : 0.3623 || loss_t_decoder3/batch : 0.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2075 || loss_t_decoder2/batch : 0.2892 || loss_t_decoder3/batch : 0.5176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3107 || loss_t_decoder2/batch : 0.4096 || loss_t_decoder3/batch : 0.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4386 || loss_t_decoder2/batch : 0.5475 || loss_t_decoder3/batch : 0.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5880 || loss_t_decoder2/batch : 0.6895 || loss_t_decoder3/batch : 0.9227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5263 || loss_t_decoder2/batch : 0.6272 || loss_t_decoder3/batch : 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3617 || loss_t_decoder2/batch : 0.4005 || loss_t_decoder3/batch : 0.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4641 || loss_t_decoder2/batch : 0.5219 || loss_t_decoder3/batch : 0.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3099 || loss_t_decoder2/batch : 0.4101 || loss_t_decoder3/batch : 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2626 || loss_t_decoder2/batch : 0.3433 || loss_t_decoder3/batch : 0.5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3008 || loss_t_decoder2/batch : 0.4442 || loss_t_decoder3/batch : 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2985 || loss_t_decoder2/batch : 0.4161 || loss_t_decoder3/batch : 0.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2908 || loss_t_decoder2/batch : 0.3939 || loss_t_decoder3/batch : 0.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4094 || loss_t_decoder2/batch : 0.5039 || loss_t_decoder3/batch : 0.7665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6650 || loss_t_decoder2/batch : 0.7826 || loss_t_decoder3/batch : 0.9484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2832 || loss_t_decoder2/batch : 0.3947 || loss_t_decoder3/batch : 0.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2781 || loss_t_decoder2/batch : 0.4116 || loss_t_decoder3/batch : 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3131 || loss_t_decoder2/batch : 0.4307 || loss_t_decoder3/batch : 0.6273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3789 || loss_t_decoder2/batch : 0.4312 || loss_t_decoder3/batch : 0.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1256 || loss_t_decoder2/batch : 1.1637 || loss_t_decoder3/batch : 1.2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 250/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 250: 0.8389065870216914-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           250\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6221369504928589\n",
      "Cumulative loss: 0.6221369504928589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.48318928480148315\n",
      "Cumulative loss: 1.1053261756896973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.621399462223053\n",
      "Cumulative loss: 1.7267255783081055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4341248869895935\n",
      "Cumulative loss: 2.1608505249023438\n",
      "------Final validation loss after epoch 250: 0.5402126312255859-------------\n",
      "Learning rate after epoch 250: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2728 || loss_t_decoder2/batch : 0.3589 || loss_t_decoder3/batch : 0.5317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):   3%|▎         | 1/35 [00:05<02:59,  5.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5132 || loss_t_decoder2/batch : 0.6239 || loss_t_decoder3/batch : 0.8124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):   6%|▌         | 2/35 [00:08<02:16,  4.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2526 || loss_t_decoder2/batch : 0.3566 || loss_t_decoder3/batch : 0.5847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):   9%|▊         | 3/35 [00:11<02:01,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4956 || loss_t_decoder2/batch : 0.5726 || loss_t_decoder3/batch : 0.7408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5741 || loss_t_decoder2/batch : 0.6525 || loss_t_decoder3/batch : 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4463 || loss_t_decoder2/batch : 0.5092 || loss_t_decoder3/batch : 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2713 || loss_t_decoder2/batch : 0.3996 || loss_t_decoder3/batch : 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3243 || loss_t_decoder2/batch : 0.4273 || loss_t_decoder3/batch : 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8178 || loss_t_decoder2/batch : 0.8608 || loss_t_decoder3/batch : 1.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5393 || loss_t_decoder2/batch : 0.6172 || loss_t_decoder3/batch : 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4277 || loss_t_decoder2/batch : 0.5300 || loss_t_decoder3/batch : 0.7402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2400 || loss_t_decoder2/batch : 0.3444 || loss_t_decoder3/batch : 0.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2196 || loss_t_decoder2/batch : 0.3056 || loss_t_decoder3/batch : 0.4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4154 || loss_t_decoder2/batch : 0.5360 || loss_t_decoder3/batch : 0.7806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4739 || loss_t_decoder2/batch : 0.5702 || loss_t_decoder3/batch : 0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2771 || loss_t_decoder2/batch : 0.3615 || loss_t_decoder3/batch : 0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2112 || loss_t_decoder2/batch : 0.2879 || loss_t_decoder3/batch : 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3095 || loss_t_decoder2/batch : 0.4089 || loss_t_decoder3/batch : 0.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4579 || loss_t_decoder2/batch : 0.5651 || loss_t_decoder3/batch : 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5827 || loss_t_decoder2/batch : 0.6847 || loss_t_decoder3/batch : 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5278 || loss_t_decoder2/batch : 0.6216 || loss_t_decoder3/batch : 0.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3618 || loss_t_decoder2/batch : 0.4023 || loss_t_decoder3/batch : 0.5320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4586 || loss_t_decoder2/batch : 0.5105 || loss_t_decoder3/batch : 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3083 || loss_t_decoder2/batch : 0.4089 || loss_t_decoder3/batch : 0.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2613 || loss_t_decoder2/batch : 0.3439 || loss_t_decoder3/batch : 0.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3050 || loss_t_decoder2/batch : 0.4389 || loss_t_decoder3/batch : 0.6978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2910 || loss_t_decoder2/batch : 0.4072 || loss_t_decoder3/batch : 0.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2789 || loss_t_decoder2/batch : 0.3868 || loss_t_decoder3/batch : 0.5670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4083 || loss_t_decoder2/batch : 0.5028 || loss_t_decoder3/batch : 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6690 || loss_t_decoder2/batch : 0.7914 || loss_t_decoder3/batch : 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2751 || loss_t_decoder2/batch : 0.3872 || loss_t_decoder3/batch : 0.5830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2784 || loss_t_decoder2/batch : 0.4116 || loss_t_decoder3/batch : 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3128 || loss_t_decoder2/batch : 0.4321 || loss_t_decoder3/batch : 0.6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3744 || loss_t_decoder2/batch : 0.4285 || loss_t_decoder3/batch : 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1256 || loss_t_decoder2/batch : 1.1636 || loss_t_decoder3/batch : 1.2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 251/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 251: 0.83813556432724-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           251\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6234419345855713\n",
      "Cumulative loss: 0.6234419345855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.484292209148407\n",
      "Cumulative loss: 1.107734203338623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6230316162109375\n",
      "Cumulative loss: 1.7307658195495605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43328529596328735\n",
      "Cumulative loss: 2.164051055908203\n",
      "------Final validation loss after epoch 251: 0.5410127639770508-------------\n",
      "Learning rate after epoch 251: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2867 || loss_t_decoder2/batch : 0.3715 || loss_t_decoder3/batch : 0.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):   3%|▎         | 1/35 [00:05<02:57,  5.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5098 || loss_t_decoder2/batch : 0.6265 || loss_t_decoder3/batch : 0.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):   6%|▌         | 2/35 [00:08<02:16,  4.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2530 || loss_t_decoder2/batch : 0.3569 || loss_t_decoder3/batch : 0.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):   9%|▊         | 3/35 [00:11<02:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4890 || loss_t_decoder2/batch : 0.5733 || loss_t_decoder3/batch : 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5094 || loss_t_decoder2/batch : 0.5945 || loss_t_decoder3/batch : 0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4215 || loss_t_decoder2/batch : 0.4824 || loss_t_decoder3/batch : 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2572 || loss_t_decoder2/batch : 0.3901 || loss_t_decoder3/batch : 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3219 || loss_t_decoder2/batch : 0.4238 || loss_t_decoder3/batch : 0.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8079 || loss_t_decoder2/batch : 0.8539 || loss_t_decoder3/batch : 1.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5357 || loss_t_decoder2/batch : 0.6121 || loss_t_decoder3/batch : 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4202 || loss_t_decoder2/batch : 0.5258 || loss_t_decoder3/batch : 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2398 || loss_t_decoder2/batch : 0.3423 || loss_t_decoder3/batch : 0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2122 || loss_t_decoder2/batch : 0.2966 || loss_t_decoder3/batch : 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4205 || loss_t_decoder2/batch : 0.5344 || loss_t_decoder3/batch : 0.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4788 || loss_t_decoder2/batch : 0.5798 || loss_t_decoder3/batch : 0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2834 || loss_t_decoder2/batch : 0.3630 || loss_t_decoder3/batch : 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2063 || loss_t_decoder2/batch : 0.2882 || loss_t_decoder3/batch : 0.5165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3195 || loss_t_decoder2/batch : 0.4163 || loss_t_decoder3/batch : 0.6178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4541 || loss_t_decoder2/batch : 0.5640 || loss_t_decoder3/batch : 0.7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5866 || loss_t_decoder2/batch : 0.6873 || loss_t_decoder3/batch : 0.9090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5415 || loss_t_decoder2/batch : 0.6359 || loss_t_decoder3/batch : 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3615 || loss_t_decoder2/batch : 0.3977 || loss_t_decoder3/batch : 0.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4569 || loss_t_decoder2/batch : 0.5095 || loss_t_decoder3/batch : 0.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3098 || loss_t_decoder2/batch : 0.4107 || loss_t_decoder3/batch : 0.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2619 || loss_t_decoder2/batch : 0.3442 || loss_t_decoder3/batch : 0.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2980 || loss_t_decoder2/batch : 0.4375 || loss_t_decoder3/batch : 0.6949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3015 || loss_t_decoder2/batch : 0.4165 || loss_t_decoder3/batch : 0.6761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2795 || loss_t_decoder2/batch : 0.3880 || loss_t_decoder3/batch : 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4228 || loss_t_decoder2/batch : 0.5194 || loss_t_decoder3/batch : 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6674 || loss_t_decoder2/batch : 0.7911 || loss_t_decoder3/batch : 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2807 || loss_t_decoder2/batch : 0.3935 || loss_t_decoder3/batch : 0.5858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2773 || loss_t_decoder2/batch : 0.4115 || loss_t_decoder3/batch : 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3179 || loss_t_decoder2/batch : 0.4359 || loss_t_decoder3/batch : 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3746 || loss_t_decoder2/batch : 0.4276 || loss_t_decoder3/batch : 0.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1254 || loss_t_decoder2/batch : 1.1640 || loss_t_decoder3/batch : 1.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 252/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 252: 0.834945856673377-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           252\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6240724921226501\n",
      "Cumulative loss: 0.6240724921226501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4826306104660034\n",
      "Cumulative loss: 1.1067030429840088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6217907667160034\n",
      "Cumulative loss: 1.7284938097000122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4333987236022949\n",
      "Cumulative loss: 2.1618924140930176\n",
      "------Final validation loss after epoch 252: 0.5404731035232544-------------\n",
      "Learning rate after epoch 252: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2774 || loss_t_decoder2/batch : 0.3604 || loss_t_decoder3/batch : 0.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):   3%|▎         | 1/35 [00:05<03:08,  5.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5121 || loss_t_decoder2/batch : 0.6237 || loss_t_decoder3/batch : 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):   6%|▌         | 2/35 [00:08<02:20,  4.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2509 || loss_t_decoder2/batch : 0.3534 || loss_t_decoder3/batch : 0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):   9%|▊         | 3/35 [00:12<02:02,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4868 || loss_t_decoder2/batch : 0.5712 || loss_t_decoder3/batch : 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5077 || loss_t_decoder2/batch : 0.5923 || loss_t_decoder3/batch : 0.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4206 || loss_t_decoder2/batch : 0.4805 || loss_t_decoder3/batch : 0.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2689 || loss_t_decoder2/batch : 0.4020 || loss_t_decoder3/batch : 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3076 || loss_t_decoder2/batch : 0.4150 || loss_t_decoder3/batch : 0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  23%|██▎       | 8/35 [00:29<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7969 || loss_t_decoder2/batch : 0.8332 || loss_t_decoder3/batch : 0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5346 || loss_t_decoder2/batch : 0.6112 || loss_t_decoder3/batch : 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4314 || loss_t_decoder2/batch : 0.5327 || loss_t_decoder3/batch : 0.7379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2396 || loss_t_decoder2/batch : 0.3436 || loss_t_decoder3/batch : 0.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2153 || loss_t_decoder2/batch : 0.3004 || loss_t_decoder3/batch : 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4172 || loss_t_decoder2/batch : 0.5318 || loss_t_decoder3/batch : 0.7535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4750 || loss_t_decoder2/batch : 0.5686 || loss_t_decoder3/batch : 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2810 || loss_t_decoder2/batch : 0.3596 || loss_t_decoder3/batch : 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2047 || loss_t_decoder2/batch : 0.2875 || loss_t_decoder3/batch : 0.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3079 || loss_t_decoder2/batch : 0.4062 || loss_t_decoder3/batch : 0.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4377 || loss_t_decoder2/batch : 0.5440 || loss_t_decoder3/batch : 0.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5800 || loss_t_decoder2/batch : 0.6851 || loss_t_decoder3/batch : 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5240 || loss_t_decoder2/batch : 0.6167 || loss_t_decoder3/batch : 0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3596 || loss_t_decoder2/batch : 0.3963 || loss_t_decoder3/batch : 0.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4627 || loss_t_decoder2/batch : 0.5155 || loss_t_decoder3/batch : 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3188 || loss_t_decoder2/batch : 0.4188 || loss_t_decoder3/batch : 0.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2819 || loss_t_decoder2/batch : 0.3589 || loss_t_decoder3/batch : 0.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3043 || loss_t_decoder2/batch : 0.4523 || loss_t_decoder3/batch : 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2878 || loss_t_decoder2/batch : 0.4067 || loss_t_decoder3/batch : 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2874 || loss_t_decoder2/batch : 0.3924 || loss_t_decoder3/batch : 0.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4210 || loss_t_decoder2/batch : 0.5179 || loss_t_decoder3/batch : 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6624 || loss_t_decoder2/batch : 0.7819 || loss_t_decoder3/batch : 0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2785 || loss_t_decoder2/batch : 0.3911 || loss_t_decoder3/batch : 0.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2868 || loss_t_decoder2/batch : 0.4166 || loss_t_decoder3/batch : 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3146 || loss_t_decoder2/batch : 0.4330 || loss_t_decoder3/batch : 0.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3747 || loss_t_decoder2/batch : 0.4306 || loss_t_decoder3/batch : 0.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1244 || loss_t_decoder2/batch : 1.1637 || loss_t_decoder3/batch : 1.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 253/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 253: 0.8326828675610679-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           253\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6257439255714417\n",
      "Cumulative loss: 0.6257439255714417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47832876443862915\n",
      "Cumulative loss: 1.1040726900100708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6280151009559631\n",
      "Cumulative loss: 1.7320878505706787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4359685480594635\n",
      "Cumulative loss: 2.1680564880371094\n",
      "------Final validation loss after epoch 253: 0.5420141220092773-------------\n",
      "Learning rate after epoch 253: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2757 || loss_t_decoder2/batch : 0.3590 || loss_t_decoder3/batch : 0.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):   3%|▎         | 1/35 [00:05<02:56,  5.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5130 || loss_t_decoder2/batch : 0.6305 || loss_t_decoder3/batch : 0.8021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):   6%|▌         | 2/35 [00:08<02:15,  4.11s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2619 || loss_t_decoder2/batch : 0.3578 || loss_t_decoder3/batch : 0.5843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):   9%|▊         | 3/35 [00:11<02:00,  3.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4901 || loss_t_decoder2/batch : 0.5733 || loss_t_decoder3/batch : 0.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  11%|█▏        | 4/35 [00:15<01:51,  3.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5662 || loss_t_decoder2/batch : 0.6455 || loss_t_decoder3/batch : 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  14%|█▍        | 5/35 [00:18<01:45,  3.51s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4450 || loss_t_decoder2/batch : 0.5065 || loss_t_decoder3/batch : 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  17%|█▋        | 6/35 [00:21<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2702 || loss_t_decoder2/batch : 0.4015 || loss_t_decoder3/batch : 0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3066 || loss_t_decoder2/batch : 0.4171 || loss_t_decoder3/batch : 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8028 || loss_t_decoder2/batch : 0.8378 || loss_t_decoder3/batch : 1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5439 || loss_t_decoder2/batch : 0.6171 || loss_t_decoder3/batch : 0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4266 || loss_t_decoder2/batch : 0.5289 || loss_t_decoder3/batch : 0.7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2381 || loss_t_decoder2/batch : 0.3434 || loss_t_decoder3/batch : 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2135 || loss_t_decoder2/batch : 0.2988 || loss_t_decoder3/batch : 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4133 || loss_t_decoder2/batch : 0.5233 || loss_t_decoder3/batch : 0.7432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4745 || loss_t_decoder2/batch : 0.5692 || loss_t_decoder3/batch : 0.7389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2765 || loss_t_decoder2/batch : 0.3607 || loss_t_decoder3/batch : 0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2052 || loss_t_decoder2/batch : 0.2872 || loss_t_decoder3/batch : 0.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3074 || loss_t_decoder2/batch : 0.4121 || loss_t_decoder3/batch : 0.6039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4374 || loss_t_decoder2/batch : 0.5454 || loss_t_decoder3/batch : 0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5884 || loss_t_decoder2/batch : 0.6888 || loss_t_decoder3/batch : 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5222 || loss_t_decoder2/batch : 0.6165 || loss_t_decoder3/batch : 0.8937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3563 || loss_t_decoder2/batch : 0.3962 || loss_t_decoder3/batch : 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4555 || loss_t_decoder2/batch : 0.5083 || loss_t_decoder3/batch : 0.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3082 || loss_t_decoder2/batch : 0.4087 || loss_t_decoder3/batch : 0.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2583 || loss_t_decoder2/batch : 0.3425 || loss_t_decoder3/batch : 0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2986 || loss_t_decoder2/batch : 0.4422 || loss_t_decoder3/batch : 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2889 || loss_t_decoder2/batch : 0.4039 || loss_t_decoder3/batch : 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2799 || loss_t_decoder2/batch : 0.3881 || loss_t_decoder3/batch : 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4191 || loss_t_decoder2/batch : 0.5156 || loss_t_decoder3/batch : 0.7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6631 || loss_t_decoder2/batch : 0.7870 || loss_t_decoder3/batch : 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2935 || loss_t_decoder2/batch : 0.4078 || loss_t_decoder3/batch : 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2751 || loss_t_decoder2/batch : 0.4097 || loss_t_decoder3/batch : 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3101 || loss_t_decoder2/batch : 0.4312 || loss_t_decoder3/batch : 0.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3723 || loss_t_decoder2/batch : 0.4275 || loss_t_decoder3/batch : 0.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1254 || loss_t_decoder2/batch : 1.1642 || loss_t_decoder3/batch : 1.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 254/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 254: 0.8349452189036778-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           254\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:07,  2.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.624359130859375\n",
      "Cumulative loss: 0.624359130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4821808636188507\n",
      "Cumulative loss: 1.1065399646759033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.62413489818573\n",
      "Cumulative loss: 1.7306748628616333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4351021349430084\n",
      "Cumulative loss: 2.1657769680023193\n",
      "------Final validation loss after epoch 254: 0.5414442420005798-------------\n",
      "Learning rate after epoch 254: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2838 || loss_t_decoder2/batch : 0.3670 || loss_t_decoder3/batch : 0.5371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):   3%|▎         | 1/35 [00:05<03:05,  5.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5077 || loss_t_decoder2/batch : 0.6255 || loss_t_decoder3/batch : 0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):   6%|▌         | 2/35 [00:08<02:19,  4.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2594 || loss_t_decoder2/batch : 0.3543 || loss_t_decoder3/batch : 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):   9%|▊         | 3/35 [00:12<02:02,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4912 || loss_t_decoder2/batch : 0.5682 || loss_t_decoder3/batch : 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  11%|█▏        | 4/35 [00:15<01:52,  3.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5613 || loss_t_decoder2/batch : 0.6406 || loss_t_decoder3/batch : 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4413 || loss_t_decoder2/batch : 0.5049 || loss_t_decoder3/batch : 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2681 || loss_t_decoder2/batch : 0.4006 || loss_t_decoder3/batch : 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3217 || loss_t_decoder2/batch : 0.4233 || loss_t_decoder3/batch : 0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7965 || loss_t_decoder2/batch : 0.8331 || loss_t_decoder3/batch : 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5354 || loss_t_decoder2/batch : 0.6112 || loss_t_decoder3/batch : 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4290 || loss_t_decoder2/batch : 0.5306 || loss_t_decoder3/batch : 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2390 || loss_t_decoder2/batch : 0.3420 || loss_t_decoder3/batch : 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2128 || loss_t_decoder2/batch : 0.2988 || loss_t_decoder3/batch : 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4160 || loss_t_decoder2/batch : 0.5309 || loss_t_decoder3/batch : 0.7526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4739 || loss_t_decoder2/batch : 0.5688 || loss_t_decoder3/batch : 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2789 || loss_t_decoder2/batch : 0.3598 || loss_t_decoder3/batch : 0.5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2045 || loss_t_decoder2/batch : 0.2865 || loss_t_decoder3/batch : 0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3081 || loss_t_decoder2/batch : 0.4074 || loss_t_decoder3/batch : 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4537 || loss_t_decoder2/batch : 0.5588 || loss_t_decoder3/batch : 0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5784 || loss_t_decoder2/batch : 0.6832 || loss_t_decoder3/batch : 0.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5250 || loss_t_decoder2/batch : 0.6279 || loss_t_decoder3/batch : 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3703 || loss_t_decoder2/batch : 0.4177 || loss_t_decoder3/batch : 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4659 || loss_t_decoder2/batch : 0.5157 || loss_t_decoder3/batch : 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3066 || loss_t_decoder2/batch : 0.4068 || loss_t_decoder3/batch : 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2595 || loss_t_decoder2/batch : 0.3427 || loss_t_decoder3/batch : 0.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3028 || loss_t_decoder2/batch : 0.4463 || loss_t_decoder3/batch : 0.7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3012 || loss_t_decoder2/batch : 0.4155 || loss_t_decoder3/batch : 0.6748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2857 || loss_t_decoder2/batch : 0.3914 || loss_t_decoder3/batch : 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  80%|████████  | 28/35 [01:36<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4051 || loss_t_decoder2/batch : 0.4979 || loss_t_decoder3/batch : 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6581 || loss_t_decoder2/batch : 0.7788 || loss_t_decoder3/batch : 0.9472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2698 || loss_t_decoder2/batch : 0.3820 || loss_t_decoder3/batch : 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2759 || loss_t_decoder2/batch : 0.4078 || loss_t_decoder3/batch : 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3118 || loss_t_decoder2/batch : 0.4324 || loss_t_decoder3/batch : 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3727 || loss_t_decoder2/batch : 0.4308 || loss_t_decoder3/batch : 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1236 || loss_t_decoder2/batch : 1.1641 || loss_t_decoder3/batch : 1.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 255/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 255: 0.8348424213273185-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           255\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6279047727584839\n",
      "Cumulative loss: 0.6279047727584839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.479790061712265\n",
      "Cumulative loss: 1.1076948642730713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.32s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6293154954910278\n",
      "Cumulative loss: 1.7370103597640991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4345661997795105\n",
      "Cumulative loss: 2.171576499938965\n",
      "------Final validation loss after epoch 255: 0.5428941249847412-------------\n",
      "Learning rate after epoch 255: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2846 || loss_t_decoder2/batch : 0.3693 || loss_t_decoder3/batch : 0.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):   3%|▎         | 1/35 [00:05<02:59,  5.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5066 || loss_t_decoder2/batch : 0.6249 || loss_t_decoder3/batch : 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):   6%|▌         | 2/35 [00:08<02:16,  4.14s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2562 || loss_t_decoder2/batch : 0.3534 || loss_t_decoder3/batch : 0.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):   9%|▊         | 3/35 [00:11<02:01,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4871 || loss_t_decoder2/batch : 0.5718 || loss_t_decoder3/batch : 0.7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  11%|█▏        | 4/35 [00:15<01:52,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5604 || loss_t_decoder2/batch : 0.6385 || loss_t_decoder3/batch : 0.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4420 || loss_t_decoder2/batch : 0.5039 || loss_t_decoder3/batch : 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  17%|█▋        | 6/35 [00:22<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2568 || loss_t_decoder2/batch : 0.3895 || loss_t_decoder3/batch : 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3217 || loss_t_decoder2/batch : 0.4245 || loss_t_decoder3/batch : 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7911 || loss_t_decoder2/batch : 0.8304 || loss_t_decoder3/batch : 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5374 || loss_t_decoder2/batch : 0.6153 || loss_t_decoder3/batch : 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4227 || loss_t_decoder2/batch : 0.5261 || loss_t_decoder3/batch : 0.7323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2391 || loss_t_decoder2/batch : 0.3422 || loss_t_decoder3/batch : 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2134 || loss_t_decoder2/batch : 0.2986 || loss_t_decoder3/batch : 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4164 || loss_t_decoder2/batch : 0.5310 || loss_t_decoder3/batch : 0.7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4732 || loss_t_decoder2/batch : 0.5681 || loss_t_decoder3/batch : 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2782 || loss_t_decoder2/batch : 0.3590 || loss_t_decoder3/batch : 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2056 || loss_t_decoder2/batch : 0.2849 || loss_t_decoder3/batch : 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3075 || loss_t_decoder2/batch : 0.4057 || loss_t_decoder3/batch : 0.5954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4378 || loss_t_decoder2/batch : 0.5407 || loss_t_decoder3/batch : 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5797 || loss_t_decoder2/batch : 0.6842 || loss_t_decoder3/batch : 0.9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5142 || loss_t_decoder2/batch : 0.6199 || loss_t_decoder3/batch : 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3589 || loss_t_decoder2/batch : 0.4003 || loss_t_decoder3/batch : 0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4612 || loss_t_decoder2/batch : 0.5141 || loss_t_decoder3/batch : 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3069 || loss_t_decoder2/batch : 0.4076 || loss_t_decoder3/batch : 0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2563 || loss_t_decoder2/batch : 0.3413 || loss_t_decoder3/batch : 0.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2983 || loss_t_decoder2/batch : 0.4426 || loss_t_decoder3/batch : 0.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2987 || loss_t_decoder2/batch : 0.4137 || loss_t_decoder3/batch : 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2796 || loss_t_decoder2/batch : 0.3878 || loss_t_decoder3/batch : 0.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4021 || loss_t_decoder2/batch : 0.4963 || loss_t_decoder3/batch : 0.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6526 || loss_t_decoder2/batch : 0.7728 || loss_t_decoder3/batch : 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2768 || loss_t_decoder2/batch : 0.3886 || loss_t_decoder3/batch : 0.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2757 || loss_t_decoder2/batch : 0.4123 || loss_t_decoder3/batch : 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3113 || loss_t_decoder2/batch : 0.4320 || loss_t_decoder3/batch : 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3712 || loss_t_decoder2/batch : 0.4255 || loss_t_decoder3/batch : 0.6045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1218 || loss_t_decoder2/batch : 1.1635 || loss_t_decoder3/batch : 1.2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 256/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 256: 0.8306625366210938-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           256\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6273221969604492\n",
      "Cumulative loss: 0.6273221969604492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47948306798934937\n",
      "Cumulative loss: 1.1068053245544434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6327588558197021\n",
      "Cumulative loss: 1.7395641803741455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4345102608203888\n",
      "Cumulative loss: 2.174074411392212\n",
      "------Final validation loss after epoch 256: 0.543518602848053-------------\n",
      "Learning rate after epoch 256: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2900 || loss_t_decoder2/batch : 0.3720 || loss_t_decoder3/batch : 0.5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):   3%|▎         | 1/35 [00:05<03:06,  5.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5114 || loss_t_decoder2/batch : 0.6239 || loss_t_decoder3/batch : 0.8112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):   6%|▌         | 2/35 [00:08<02:19,  4.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2494 || loss_t_decoder2/batch : 0.3514 || loss_t_decoder3/batch : 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):   9%|▊         | 3/35 [00:12<02:02,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4855 || loss_t_decoder2/batch : 0.5698 || loss_t_decoder3/batch : 0.7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  11%|█▏        | 4/35 [00:15<01:52,  3.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5509 || loss_t_decoder2/batch : 0.6319 || loss_t_decoder3/batch : 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4200 || loss_t_decoder2/batch : 0.4805 || loss_t_decoder3/batch : 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2550 || loss_t_decoder2/batch : 0.3914 || loss_t_decoder3/batch : 0.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3063 || loss_t_decoder2/batch : 0.4165 || loss_t_decoder3/batch : 0.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7953 || loss_t_decoder2/batch : 0.8332 || loss_t_decoder3/batch : 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5341 || loss_t_decoder2/batch : 0.6110 || loss_t_decoder3/batch : 0.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4180 || loss_t_decoder2/batch : 0.5237 || loss_t_decoder3/batch : 0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2410 || loss_t_decoder2/batch : 0.3436 || loss_t_decoder3/batch : 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2094 || loss_t_decoder2/batch : 0.2949 || loss_t_decoder3/batch : 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4120 || loss_t_decoder2/batch : 0.5285 || loss_t_decoder3/batch : 0.7529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4715 || loss_t_decoder2/batch : 0.5673 || loss_t_decoder3/batch : 0.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2768 || loss_t_decoder2/batch : 0.3590 || loss_t_decoder3/batch : 0.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2038 || loss_t_decoder2/batch : 0.2863 || loss_t_decoder3/batch : 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3064 || loss_t_decoder2/batch : 0.4038 || loss_t_decoder3/batch : 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4482 || loss_t_decoder2/batch : 0.5557 || loss_t_decoder3/batch : 0.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6023 || loss_t_decoder2/batch : 0.7017 || loss_t_decoder3/batch : 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5097 || loss_t_decoder2/batch : 0.6153 || loss_t_decoder3/batch : 0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3757 || loss_t_decoder2/batch : 0.4109 || loss_t_decoder3/batch : 0.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4530 || loss_t_decoder2/batch : 0.5066 || loss_t_decoder3/batch : 0.6558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3062 || loss_t_decoder2/batch : 0.4061 || loss_t_decoder3/batch : 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2618 || loss_t_decoder2/batch : 0.3427 || loss_t_decoder3/batch : 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2965 || loss_t_decoder2/batch : 0.4366 || loss_t_decoder3/batch : 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2894 || loss_t_decoder2/batch : 0.4064 || loss_t_decoder3/batch : 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2787 || loss_t_decoder2/batch : 0.3868 || loss_t_decoder3/batch : 0.5692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4184 || loss_t_decoder2/batch : 0.5127 || loss_t_decoder3/batch : 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6628 || loss_t_decoder2/batch : 0.7863 || loss_t_decoder3/batch : 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2763 || loss_t_decoder2/batch : 0.3878 || loss_t_decoder3/batch : 0.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2752 || loss_t_decoder2/batch : 0.4103 || loss_t_decoder3/batch : 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3085 || loss_t_decoder2/batch : 0.4306 || loss_t_decoder3/batch : 0.6189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3726 || loss_t_decoder2/batch : 0.4288 || loss_t_decoder3/batch : 0.6026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1255 || loss_t_decoder2/batch : 1.1634 || loss_t_decoder3/batch : 1.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 257/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 257: 0.8310479096003941-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           257\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6273924112319946\n",
      "Cumulative loss: 0.6273924112319946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47886359691619873\n",
      "Cumulative loss: 1.1062560081481934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6325048804283142\n",
      "Cumulative loss: 1.7387609481811523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43453535437583923\n",
      "Cumulative loss: 2.1732962131500244\n",
      "------Final validation loss after epoch 257: 0.5433240532875061-------------\n",
      "Learning rate after epoch 257: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2739 || loss_t_decoder2/batch : 0.3576 || loss_t_decoder3/batch : 0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):   3%|▎         | 1/35 [00:05<03:00,  5.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5060 || loss_t_decoder2/batch : 0.6200 || loss_t_decoder3/batch : 0.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):   6%|▌         | 2/35 [00:08<02:17,  4.16s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2514 || loss_t_decoder2/batch : 0.3548 || loss_t_decoder3/batch : 0.5843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):   9%|▊         | 3/35 [00:12<02:01,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4899 || loss_t_decoder2/batch : 0.5680 || loss_t_decoder3/batch : 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5450 || loss_t_decoder2/batch : 0.6260 || loss_t_decoder3/batch : 0.8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  14%|█▍        | 5/35 [00:18<01:45,  3.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4157 || loss_t_decoder2/batch : 0.4766 || loss_t_decoder3/batch : 0.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2563 || loss_t_decoder2/batch : 0.3888 || loss_t_decoder3/batch : 0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3058 || loss_t_decoder2/batch : 0.4161 || loss_t_decoder3/batch : 0.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7866 || loss_t_decoder2/batch : 0.8252 || loss_t_decoder3/batch : 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5339 || loss_t_decoder2/batch : 0.6116 || loss_t_decoder3/batch : 0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4299 || loss_t_decoder2/batch : 0.5318 || loss_t_decoder3/batch : 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2381 || loss_t_decoder2/batch : 0.3415 || loss_t_decoder3/batch : 0.5602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2140 || loss_t_decoder2/batch : 0.3001 || loss_t_decoder3/batch : 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4132 || loss_t_decoder2/batch : 0.5287 || loss_t_decoder3/batch : 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4716 || loss_t_decoder2/batch : 0.5670 || loss_t_decoder3/batch : 0.7369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2754 || loss_t_decoder2/batch : 0.3595 || loss_t_decoder3/batch : 0.5618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2078 || loss_t_decoder2/batch : 0.2860 || loss_t_decoder3/batch : 0.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3083 || loss_t_decoder2/batch : 0.4059 || loss_t_decoder3/batch : 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4500 || loss_t_decoder2/batch : 0.5588 || loss_t_decoder3/batch : 0.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5784 || loss_t_decoder2/batch : 0.6835 || loss_t_decoder3/batch : 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5103 || loss_t_decoder2/batch : 0.6133 || loss_t_decoder3/batch : 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  60%|██████    | 21/35 [01:12<00:46,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3566 || loss_t_decoder2/batch : 0.3990 || loss_t_decoder3/batch : 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4623 || loss_t_decoder2/batch : 0.5144 || loss_t_decoder3/batch : 0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3082 || loss_t_decoder2/batch : 0.4072 || loss_t_decoder3/batch : 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2588 || loss_t_decoder2/batch : 0.3420 || loss_t_decoder3/batch : 0.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3109 || loss_t_decoder2/batch : 0.4560 || loss_t_decoder3/batch : 0.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2886 || loss_t_decoder2/batch : 0.4077 || loss_t_decoder3/batch : 0.6688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2872 || loss_t_decoder2/batch : 0.3919 || loss_t_decoder3/batch : 0.5721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3994 || loss_t_decoder2/batch : 0.4939 || loss_t_decoder3/batch : 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6656 || loss_t_decoder2/batch : 0.7913 || loss_t_decoder3/batch : 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2699 || loss_t_decoder2/batch : 0.3821 || loss_t_decoder3/batch : 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2758 || loss_t_decoder2/batch : 0.4124 || loss_t_decoder3/batch : 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3091 || loss_t_decoder2/batch : 0.4310 || loss_t_decoder3/batch : 0.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3691 || loss_t_decoder2/batch : 0.4260 || loss_t_decoder3/batch : 0.6068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1235 || loss_t_decoder2/batch : 1.1634 || loss_t_decoder3/batch : 1.2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 258/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 258: 0.8284746280738285-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           258\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6275152564048767\n",
      "Cumulative loss: 0.6275152564048767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4779583215713501\n",
      "Cumulative loss: 1.105473518371582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6282985210418701\n",
      "Cumulative loss: 1.7337720394134521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43435508012771606\n",
      "Cumulative loss: 2.1681270599365234\n",
      "------Final validation loss after epoch 258: 0.5420317649841309-------------\n",
      "Learning rate after epoch 258: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2943 || loss_t_decoder2/batch : 0.3678 || loss_t_decoder3/batch : 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):   3%|▎         | 1/35 [00:05<03:05,  5.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5151 || loss_t_decoder2/batch : 0.6345 || loss_t_decoder3/batch : 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):   6%|▌         | 2/35 [00:08<02:19,  4.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2564 || loss_t_decoder2/batch : 0.3536 || loss_t_decoder3/batch : 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):   9%|▊         | 3/35 [00:12<02:02,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4879 || loss_t_decoder2/batch : 0.5668 || loss_t_decoder3/batch : 0.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  11%|█▏        | 4/35 [00:15<01:52,  3.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5014 || loss_t_decoder2/batch : 0.5847 || loss_t_decoder3/batch : 0.8138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4391 || loss_t_decoder2/batch : 0.5047 || loss_t_decoder3/batch : 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2675 || loss_t_decoder2/batch : 0.3974 || loss_t_decoder3/batch : 0.6359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3062 || loss_t_decoder2/batch : 0.4152 || loss_t_decoder3/batch : 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8055 || loss_t_decoder2/batch : 0.8484 || loss_t_decoder3/batch : 1.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5341 || loss_t_decoder2/batch : 0.6136 || loss_t_decoder3/batch : 0.7920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4276 || loss_t_decoder2/batch : 0.5294 || loss_t_decoder3/batch : 0.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2518 || loss_t_decoder2/batch : 0.3483 || loss_t_decoder3/batch : 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2102 || loss_t_decoder2/batch : 0.2967 || loss_t_decoder3/batch : 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4049 || loss_t_decoder2/batch : 0.5174 || loss_t_decoder3/batch : 0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4712 || loss_t_decoder2/batch : 0.5660 || loss_t_decoder3/batch : 0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2753 || loss_t_decoder2/batch : 0.3568 || loss_t_decoder3/batch : 0.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2028 || loss_t_decoder2/batch : 0.2859 || loss_t_decoder3/batch : 0.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3062 || loss_t_decoder2/batch : 0.4031 || loss_t_decoder3/batch : 0.5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4469 || loss_t_decoder2/batch : 0.5549 || loss_t_decoder3/batch : 0.7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5772 || loss_t_decoder2/batch : 0.6821 || loss_t_decoder3/batch : 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5075 || loss_t_decoder2/batch : 0.6123 || loss_t_decoder3/batch : 0.8884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3536 || loss_t_decoder2/batch : 0.3920 || loss_t_decoder3/batch : 0.5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4760 || loss_t_decoder2/batch : 0.5258 || loss_t_decoder3/batch : 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3067 || loss_t_decoder2/batch : 0.4079 || loss_t_decoder3/batch : 0.6340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2601 || loss_t_decoder2/batch : 0.3430 || loss_t_decoder3/batch : 0.5531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3008 || loss_t_decoder2/batch : 0.4442 || loss_t_decoder3/batch : 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2969 || loss_t_decoder2/batch : 0.4135 || loss_t_decoder3/batch : 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2842 || loss_t_decoder2/batch : 0.3907 || loss_t_decoder3/batch : 0.5703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  80%|████████  | 28/35 [01:36<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4138 || loss_t_decoder2/batch : 0.5115 || loss_t_decoder3/batch : 0.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6590 || loss_t_decoder2/batch : 0.7843 || loss_t_decoder3/batch : 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2662 || loss_t_decoder2/batch : 0.3791 || loss_t_decoder3/batch : 0.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2735 || loss_t_decoder2/batch : 0.4098 || loss_t_decoder3/batch : 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3078 || loss_t_decoder2/batch : 0.4282 || loss_t_decoder3/batch : 0.6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3684 || loss_t_decoder2/batch : 0.4250 || loss_t_decoder3/batch : 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1232 || loss_t_decoder2/batch : 1.1632 || loss_t_decoder3/batch : 1.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 259/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 259: 0.8297937904085432-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           259\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6244094967842102\n",
      "Cumulative loss: 0.6244094967842102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47585105895996094\n",
      "Cumulative loss: 1.1002604961395264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6226145029067993\n",
      "Cumulative loss: 1.7228749990463257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4358782470226288\n",
      "Cumulative loss: 2.1587531566619873\n",
      "------Final validation loss after epoch 259: 0.5396882891654968-------------\n",
      "Learning rate after epoch 259: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2793 || loss_t_decoder2/batch : 0.3626 || loss_t_decoder3/batch : 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):   3%|▎         | 1/35 [00:05<03:07,  5.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5069 || loss_t_decoder2/batch : 0.6200 || loss_t_decoder3/batch : 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):   6%|▌         | 2/35 [00:08<02:20,  4.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2490 || loss_t_decoder2/batch : 0.3511 || loss_t_decoder3/batch : 0.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):   9%|▊         | 3/35 [00:12<02:02,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4779 || loss_t_decoder2/batch : 0.5651 || loss_t_decoder3/batch : 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4981 || loss_t_decoder2/batch : 0.5820 || loss_t_decoder3/batch : 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4139 || loss_t_decoder2/batch : 0.4750 || loss_t_decoder3/batch : 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2667 || loss_t_decoder2/batch : 0.3994 || loss_t_decoder3/batch : 0.6368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3046 || loss_t_decoder2/batch : 0.4145 || loss_t_decoder3/batch : 0.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  23%|██▎       | 8/35 [00:29<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7812 || loss_t_decoder2/batch : 0.8207 || loss_t_decoder3/batch : 0.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5344 || loss_t_decoder2/batch : 0.6140 || loss_t_decoder3/batch : 0.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4581 || loss_t_decoder2/batch : 0.5534 || loss_t_decoder3/batch : 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2535 || loss_t_decoder2/batch : 0.3491 || loss_t_decoder3/batch : 0.5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2139 || loss_t_decoder2/batch : 0.3003 || loss_t_decoder3/batch : 0.4523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  37%|███▋      | 13/35 [00:45<01:14,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4077 || loss_t_decoder2/batch : 0.5309 || loss_t_decoder3/batch : 0.7745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4716 || loss_t_decoder2/batch : 0.5652 || loss_t_decoder3/batch : 0.7355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2813 || loss_t_decoder2/batch : 0.3671 || loss_t_decoder3/batch : 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2050 || loss_t_decoder2/batch : 0.2864 || loss_t_decoder3/batch : 0.4957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3049 || loss_t_decoder2/batch : 0.4028 || loss_t_decoder3/batch : 0.5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4455 || loss_t_decoder2/batch : 0.5528 || loss_t_decoder3/batch : 0.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5762 || loss_t_decoder2/batch : 0.6826 || loss_t_decoder3/batch : 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5126 || loss_t_decoder2/batch : 0.6089 || loss_t_decoder3/batch : 0.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3510 || loss_t_decoder2/batch : 0.3950 || loss_t_decoder3/batch : 0.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4526 || loss_t_decoder2/batch : 0.5065 || loss_t_decoder3/batch : 0.6558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3054 || loss_t_decoder2/batch : 0.4062 || loss_t_decoder3/batch : 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2571 || loss_t_decoder2/batch : 0.3402 || loss_t_decoder3/batch : 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2996 || loss_t_decoder2/batch : 0.4432 || loss_t_decoder3/batch : 0.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2959 || loss_t_decoder2/batch : 0.4123 || loss_t_decoder3/batch : 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2751 || loss_t_decoder2/batch : 0.3855 || loss_t_decoder3/batch : 0.5672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  80%|████████  | 28/35 [01:36<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4130 || loss_t_decoder2/batch : 0.5107 || loss_t_decoder3/batch : 0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7412 || loss_t_decoder2/batch : 0.8376 || loss_t_decoder3/batch : 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2638 || loss_t_decoder2/batch : 0.3765 || loss_t_decoder3/batch : 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2733 || loss_t_decoder2/batch : 0.4112 || loss_t_decoder3/batch : 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3112 || loss_t_decoder2/batch : 0.4340 || loss_t_decoder3/batch : 0.6189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3678 || loss_t_decoder2/batch : 0.4245 || loss_t_decoder3/batch : 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1201 || loss_t_decoder2/batch : 1.1624 || loss_t_decoder3/batch : 1.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 260/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 260: 0.8290126672812871-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           260\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6314462423324585\n",
      "Cumulative loss: 0.6314462423324585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.46724313497543335\n",
      "Cumulative loss: 1.098689317703247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6402797698974609\n",
      "Cumulative loss: 1.738969087600708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43757903575897217\n",
      "Cumulative loss: 2.1765480041503906\n",
      "------Final validation loss after epoch 260: 0.5441370010375977-------------\n",
      "Learning rate after epoch 260: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2844 || loss_t_decoder2/batch : 0.3660 || loss_t_decoder3/batch : 0.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):   3%|▎         | 1/35 [00:05<03:00,  5.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5098 || loss_t_decoder2/batch : 0.6230 || loss_t_decoder3/batch : 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):   6%|▌         | 2/35 [00:08<02:17,  4.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2519 || loss_t_decoder2/batch : 0.3551 || loss_t_decoder3/batch : 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):   9%|▊         | 3/35 [00:12<02:01,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4858 || loss_t_decoder2/batch : 0.5674 || loss_t_decoder3/batch : 0.7431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5514 || loss_t_decoder2/batch : 0.6305 || loss_t_decoder3/batch : 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4199 || loss_t_decoder2/batch : 0.4788 || loss_t_decoder3/batch : 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2679 || loss_t_decoder2/batch : 0.3960 || loss_t_decoder3/batch : 0.6334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3220 || loss_t_decoder2/batch : 0.4245 || loss_t_decoder3/batch : 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8017 || loss_t_decoder2/batch : 0.8383 || loss_t_decoder3/batch : 1.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5399 || loss_t_decoder2/batch : 0.6162 || loss_t_decoder3/batch : 0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4165 || loss_t_decoder2/batch : 0.5210 || loss_t_decoder3/batch : 0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2536 || loss_t_decoder2/batch : 0.3498 || loss_t_decoder3/batch : 0.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2086 || loss_t_decoder2/batch : 0.2952 || loss_t_decoder3/batch : 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4109 || loss_t_decoder2/batch : 0.5256 || loss_t_decoder3/batch : 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4703 || loss_t_decoder2/batch : 0.5646 || loss_t_decoder3/batch : 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2783 || loss_t_decoder2/batch : 0.3561 || loss_t_decoder3/batch : 0.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2019 || loss_t_decoder2/batch : 0.2864 || loss_t_decoder3/batch : 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3072 || loss_t_decoder2/batch : 0.4059 || loss_t_decoder3/batch : 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4524 || loss_t_decoder2/batch : 0.5543 || loss_t_decoder3/batch : 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5782 || loss_t_decoder2/batch : 0.6829 || loss_t_decoder3/batch : 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5137 || loss_t_decoder2/batch : 0.6095 || loss_t_decoder3/batch : 0.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3520 || loss_t_decoder2/batch : 0.3944 || loss_t_decoder3/batch : 0.5260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4610 || loss_t_decoder2/batch : 0.5138 || loss_t_decoder3/batch : 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3043 || loss_t_decoder2/batch : 0.4040 || loss_t_decoder3/batch : 0.6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2559 || loss_t_decoder2/batch : 0.3407 || loss_t_decoder3/batch : 0.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2956 || loss_t_decoder2/batch : 0.4355 || loss_t_decoder3/batch : 0.6953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2969 || loss_t_decoder2/batch : 0.4125 || loss_t_decoder3/batch : 0.6730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2860 || loss_t_decoder2/batch : 0.3913 || loss_t_decoder3/batch : 0.5713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3972 || loss_t_decoder2/batch : 0.4927 || loss_t_decoder3/batch : 0.7537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6545 || loss_t_decoder2/batch : 0.7676 || loss_t_decoder3/batch : 0.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2756 || loss_t_decoder2/batch : 0.3863 || loss_t_decoder3/batch : 0.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2786 || loss_t_decoder2/batch : 0.4084 || loss_t_decoder3/batch : 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3054 || loss_t_decoder2/batch : 0.4272 || loss_t_decoder3/batch : 0.6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3703 || loss_t_decoder2/batch : 0.4290 || loss_t_decoder3/batch : 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1237 || loss_t_decoder2/batch : 1.1630 || loss_t_decoder3/batch : 1.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 261/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 261: 0.8289982983044215-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           261\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6266671419143677\n",
      "Cumulative loss: 0.6266671419143677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4809954762458801\n",
      "Cumulative loss: 1.1076626777648926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6321053504943848\n",
      "Cumulative loss: 1.7397680282592773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4354155361652374\n",
      "Cumulative loss: 2.1751835346221924\n",
      "------Final validation loss after epoch 261: 0.5437958836555481-------------\n",
      "Learning rate after epoch 261: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2799 || loss_t_decoder2/batch : 0.3641 || loss_t_decoder3/batch : 0.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):   3%|▎         | 1/35 [00:05<02:57,  5.21s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5047 || loss_t_decoder2/batch : 0.6177 || loss_t_decoder3/batch : 0.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):   6%|▌         | 2/35 [00:08<02:15,  4.12s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2515 || loss_t_decoder2/batch : 0.3543 || loss_t_decoder3/batch : 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):   9%|▊         | 3/35 [00:11<02:00,  3.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4853 || loss_t_decoder2/batch : 0.5674 || loss_t_decoder3/batch : 0.7365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5409 || loss_t_decoder2/batch : 0.6216 || loss_t_decoder3/batch : 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4356 || loss_t_decoder2/batch : 0.5009 || loss_t_decoder3/batch : 0.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  17%|█▋        | 6/35 [00:21<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2630 || loss_t_decoder2/batch : 0.3977 || loss_t_decoder3/batch : 0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3059 || loss_t_decoder2/batch : 0.4155 || loss_t_decoder3/batch : 0.6540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7877 || loss_t_decoder2/batch : 0.8273 || loss_t_decoder3/batch : 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5314 || loss_t_decoder2/batch : 0.6117 || loss_t_decoder3/batch : 0.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4178 || loss_t_decoder2/batch : 0.5221 || loss_t_decoder3/batch : 0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2504 || loss_t_decoder2/batch : 0.3490 || loss_t_decoder3/batch : 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2112 || loss_t_decoder2/batch : 0.2976 || loss_t_decoder3/batch : 0.4535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4002 || loss_t_decoder2/batch : 0.5144 || loss_t_decoder3/batch : 0.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4794 || loss_t_decoder2/batch : 0.5780 || loss_t_decoder3/batch : 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2850 || loss_t_decoder2/batch : 0.3593 || loss_t_decoder3/batch : 0.5528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2010 || loss_t_decoder2/batch : 0.2847 || loss_t_decoder3/batch : 0.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3039 || loss_t_decoder2/batch : 0.4009 || loss_t_decoder3/batch : 0.5935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4525 || loss_t_decoder2/batch : 0.5593 || loss_t_decoder3/batch : 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5756 || loss_t_decoder2/batch : 0.6804 || loss_t_decoder3/batch : 0.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5088 || loss_t_decoder2/batch : 0.6139 || loss_t_decoder3/batch : 0.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3533 || loss_t_decoder2/batch : 0.3936 || loss_t_decoder3/batch : 0.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4705 || loss_t_decoder2/batch : 0.5214 || loss_t_decoder3/batch : 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3065 || loss_t_decoder2/batch : 0.4076 || loss_t_decoder3/batch : 0.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2541 || loss_t_decoder2/batch : 0.3399 || loss_t_decoder3/batch : 0.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3049 || loss_t_decoder2/batch : 0.4522 || loss_t_decoder3/batch : 0.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2951 || loss_t_decoder2/batch : 0.4127 || loss_t_decoder3/batch : 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2870 || loss_t_decoder2/batch : 0.3914 || loss_t_decoder3/batch : 0.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  80%|████████  | 28/35 [01:35<00:23,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4276 || loss_t_decoder2/batch : 0.5194 || loss_t_decoder3/batch : 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6615 || loss_t_decoder2/batch : 0.7804 || loss_t_decoder3/batch : 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2717 || loss_t_decoder2/batch : 0.3831 || loss_t_decoder3/batch : 0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2727 || loss_t_decoder2/batch : 0.4065 || loss_t_decoder3/batch : 0.6776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3063 || loss_t_decoder2/batch : 0.4294 || loss_t_decoder3/batch : 0.6195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3671 || loss_t_decoder2/batch : 0.4244 || loss_t_decoder3/batch : 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1237 || loss_t_decoder2/batch : 1.1630 || loss_t_decoder3/batch : 1.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 262/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 262: 0.8297554850578308-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           262\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6267872452735901\n",
      "Cumulative loss: 0.6267872452735901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.48046669363975525\n",
      "Cumulative loss: 1.107253909111023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6323560476303101\n",
      "Cumulative loss: 1.739609956741333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4354616403579712\n",
      "Cumulative loss: 2.1750717163085938\n",
      "------Final validation loss after epoch 262: 0.5437679290771484-------------\n",
      "Learning rate after epoch 262: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2724 || loss_t_decoder2/batch : 0.3563 || loss_t_decoder3/batch : 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):   3%|▎         | 1/35 [00:05<03:06,  5.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5061 || loss_t_decoder2/batch : 0.6191 || loss_t_decoder3/batch : 0.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):   6%|▌         | 2/35 [00:08<02:19,  4.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2515 || loss_t_decoder2/batch : 0.3542 || loss_t_decoder3/batch : 0.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):   9%|▊         | 3/35 [00:12<02:02,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4821 || loss_t_decoder2/batch : 0.5672 || loss_t_decoder3/batch : 0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  11%|█▏        | 4/35 [00:15<01:53,  3.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4927 || loss_t_decoder2/batch : 0.5771 || loss_t_decoder3/batch : 0.8097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  14%|█▍        | 5/35 [00:18<01:46,  3.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4359 || loss_t_decoder2/batch : 0.4986 || loss_t_decoder3/batch : 0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  17%|█▋        | 6/35 [00:22<01:40,  3.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2663 || loss_t_decoder2/batch : 0.3939 || loss_t_decoder3/batch : 0.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  20%|██        | 7/35 [00:25<01:36,  3.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3197 || loss_t_decoder2/batch : 0.4234 || loss_t_decoder3/batch : 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  23%|██▎       | 8/35 [00:28<01:32,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7838 || loss_t_decoder2/batch : 0.8237 || loss_t_decoder3/batch : 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5310 || loss_t_decoder2/batch : 0.6079 || loss_t_decoder3/batch : 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4177 || loss_t_decoder2/batch : 0.5220 || loss_t_decoder3/batch : 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  31%|███▏      | 11/35 [00:39<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2516 || loss_t_decoder2/batch : 0.3481 || loss_t_decoder3/batch : 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2127 || loss_t_decoder2/batch : 0.3000 || loss_t_decoder3/batch : 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4045 || loss_t_decoder2/batch : 0.5220 || loss_t_decoder3/batch : 0.7493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  40%|████      | 14/35 [00:49<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4853 || loss_t_decoder2/batch : 0.5767 || loss_t_decoder3/batch : 0.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2731 || loss_t_decoder2/batch : 0.3567 || loss_t_decoder3/batch : 0.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2016 || loss_t_decoder2/batch : 0.2847 || loss_t_decoder3/batch : 0.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  49%|████▊     | 17/35 [00:59<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3034 || loss_t_decoder2/batch : 0.4018 || loss_t_decoder3/batch : 0.5973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4293 || loss_t_decoder2/batch : 0.5364 || loss_t_decoder3/batch : 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5772 || loss_t_decoder2/batch : 0.6853 || loss_t_decoder3/batch : 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5058 || loss_t_decoder2/batch : 0.6039 || loss_t_decoder3/batch : 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3535 || loss_t_decoder2/batch : 0.3914 || loss_t_decoder3/batch : 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4588 || loss_t_decoder2/batch : 0.5113 || loss_t_decoder3/batch : 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3056 || loss_t_decoder2/batch : 0.4045 || loss_t_decoder3/batch : 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2540 || loss_t_decoder2/batch : 0.3400 || loss_t_decoder3/batch : 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  71%|███████▏  | 25/35 [01:26<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2970 || loss_t_decoder2/batch : 0.4419 || loss_t_decoder3/batch : 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3014 || loss_t_decoder2/batch : 0.4182 || loss_t_decoder3/batch : 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2837 || loss_t_decoder2/batch : 0.3905 || loss_t_decoder3/batch : 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  80%|████████  | 28/35 [01:36<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3945 || loss_t_decoder2/batch : 0.4915 || loss_t_decoder3/batch : 0.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6612 || loss_t_decoder2/batch : 0.7804 || loss_t_decoder3/batch : 0.9574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2639 || loss_t_decoder2/batch : 0.3763 || loss_t_decoder3/batch : 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  89%|████████▊ | 31/35 [01:46<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2736 || loss_t_decoder2/batch : 0.4089 || loss_t_decoder3/batch : 0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3055 || loss_t_decoder2/batch : 0.4268 || loss_t_decoder3/batch : 0.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3669 || loss_t_decoder2/batch : 0.4243 || loss_t_decoder3/batch : 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1256 || loss_t_decoder2/batch : 1.1627 || loss_t_decoder3/batch : 1.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 263/265): 100%|██████████| 35/35 [01:59<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 263: 0.8233656346797943-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           263\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6267824769020081\n",
      "Cumulative loss: 0.6267824769020081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.479971706867218\n",
      "Cumulative loss: 1.106754183769226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.32s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6318559050559998\n",
      "Cumulative loss: 1.738610029220581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4355309307575226\n",
      "Cumulative loss: 2.1741409301757812\n",
      "------Final validation loss after epoch 263: 0.5435352325439453-------------\n",
      "Learning rate after epoch 263: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2685 || loss_t_decoder2/batch : 0.3546 || loss_t_decoder3/batch : 0.5292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):   3%|▎         | 1/35 [00:05<02:56,  5.20s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5063 || loss_t_decoder2/batch : 0.6247 || loss_t_decoder3/batch : 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):   6%|▌         | 2/35 [00:08<02:15,  4.12s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2585 || loss_t_decoder2/batch : 0.3561 || loss_t_decoder3/batch : 0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):   9%|▊         | 3/35 [00:11<02:00,  3.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4859 || loss_t_decoder2/batch : 0.5656 || loss_t_decoder3/batch : 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  11%|█▏        | 4/35 [00:15<01:51,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4918 || loss_t_decoder2/batch : 0.5764 || loss_t_decoder3/batch : 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4357 || loss_t_decoder2/batch : 0.4990 || loss_t_decoder3/batch : 0.6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  17%|█▋        | 6/35 [00:21<01:40,  3.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2628 || loss_t_decoder2/batch : 0.3975 || loss_t_decoder3/batch : 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  20%|██        | 7/35 [00:25<01:35,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3058 || loss_t_decoder2/batch : 0.4154 || loss_t_decoder3/batch : 0.6538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  23%|██▎       | 8/35 [00:28<01:31,  3.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7807 || loss_t_decoder2/batch : 0.8195 || loss_t_decoder3/batch : 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5313 || loss_t_decoder2/batch : 0.6091 || loss_t_decoder3/batch : 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4263 || loss_t_decoder2/batch : 0.5280 || loss_t_decoder3/batch : 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2386 || loss_t_decoder2/batch : 0.3408 || loss_t_decoder3/batch : 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2152 || loss_t_decoder2/batch : 0.3000 || loss_t_decoder3/batch : 0.4602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3995 || loss_t_decoder2/batch : 0.5153 || loss_t_decoder3/batch : 0.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4703 || loss_t_decoder2/batch : 0.5684 || loss_t_decoder3/batch : 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2776 || loss_t_decoder2/batch : 0.3562 || loss_t_decoder3/batch : 0.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2009 || loss_t_decoder2/batch : 0.2851 || loss_t_decoder3/batch : 0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3064 || loss_t_decoder2/batch : 0.4037 || loss_t_decoder3/batch : 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4430 || loss_t_decoder2/batch : 0.5469 || loss_t_decoder3/batch : 0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5735 || loss_t_decoder2/batch : 0.6792 || loss_t_decoder3/batch : 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  57%|█████▋    | 20/35 [01:08<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5099 || loss_t_decoder2/batch : 0.6137 || loss_t_decoder3/batch : 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3511 || loss_t_decoder2/batch : 0.3925 || loss_t_decoder3/batch : 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4586 || loss_t_decoder2/batch : 0.5105 || loss_t_decoder3/batch : 0.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3053 || loss_t_decoder2/batch : 0.4054 || loss_t_decoder3/batch : 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2564 || loss_t_decoder2/batch : 0.3396 || loss_t_decoder3/batch : 0.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2986 || loss_t_decoder2/batch : 0.4433 || loss_t_decoder3/batch : 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2971 || loss_t_decoder2/batch : 0.4111 || loss_t_decoder3/batch : 0.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2867 || loss_t_decoder2/batch : 0.3912 || loss_t_decoder3/batch : 0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3942 || loss_t_decoder2/batch : 0.4913 || loss_t_decoder3/batch : 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6511 || loss_t_decoder2/batch : 0.7648 || loss_t_decoder3/batch : 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2720 || loss_t_decoder2/batch : 0.3837 || loss_t_decoder3/batch : 0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2726 || loss_t_decoder2/batch : 0.4085 || loss_t_decoder3/batch : 0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3155 || loss_t_decoder2/batch : 0.4382 || loss_t_decoder3/batch : 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3668 || loss_t_decoder2/batch : 0.4242 || loss_t_decoder3/batch : 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265):  97%|█████████▋| 34/35 [01:55<00:03,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1222 || loss_t_decoder2/batch : 1.1627 || loss_t_decoder3/batch : 1.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 264/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 264: 0.823023636851992-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           264\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:07,  2.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6265854835510254\n",
      "Cumulative loss: 0.6265854835510254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47996431589126587\n",
      "Cumulative loss: 1.1065497398376465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6311428546905518\n",
      "Cumulative loss: 1.7376925945281982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.4356752932071686\n",
      "Cumulative loss: 2.173367977142334\n",
      "------Final validation loss after epoch 264: 0.5433419942855835-------------\n",
      "Learning rate after epoch 264: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2834 || loss_t_decoder2/batch : 0.3655 || loss_t_decoder3/batch : 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):   3%|▎         | 1/35 [00:05<03:00,  5.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5125 || loss_t_decoder2/batch : 0.6312 || loss_t_decoder3/batch : 0.8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):   6%|▌         | 2/35 [00:08<02:17,  4.16s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2636 || loss_t_decoder2/batch : 0.3593 || loss_t_decoder3/batch : 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):   9%|▊         | 3/35 [00:12<02:01,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4853 || loss_t_decoder2/batch : 0.5672 || loss_t_decoder3/batch : 0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  11%|█▏        | 4/35 [00:15<01:52,  3.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4935 || loss_t_decoder2/batch : 0.5790 || loss_t_decoder3/batch : 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  14%|█▍        | 5/35 [00:18<01:45,  3.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4355 || loss_t_decoder2/batch : 0.4987 || loss_t_decoder3/batch : 0.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  17%|█▋        | 6/35 [00:22<01:40,  3.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2635 || loss_t_decoder2/batch : 0.3951 || loss_t_decoder3/batch : 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  20%|██        | 7/35 [00:25<01:36,  3.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3195 || loss_t_decoder2/batch : 0.4233 || loss_t_decoder3/batch : 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  23%|██▎       | 8/35 [00:28<01:31,  3.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7860 || loss_t_decoder2/batch : 0.8251 || loss_t_decoder3/batch : 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  26%|██▌       | 9/35 [00:32<01:28,  3.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5313 || loss_t_decoder2/batch : 0.6090 || loss_t_decoder3/batch : 0.7977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  29%|██▊       | 10/35 [00:35<01:24,  3.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4176 || loss_t_decoder2/batch : 0.5219 || loss_t_decoder3/batch : 0.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  31%|███▏      | 11/35 [00:38<01:20,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2385 || loss_t_decoder2/batch : 0.3407 || loss_t_decoder3/batch : 0.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  34%|███▍      | 12/35 [00:42<01:17,  3.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2123 || loss_t_decoder2/batch : 0.2996 || loss_t_decoder3/batch : 0.4521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  37%|███▋      | 13/35 [00:45<01:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4100 || loss_t_decoder2/batch : 0.5330 || loss_t_decoder3/batch : 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  40%|████      | 14/35 [00:48<01:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4795 || loss_t_decoder2/batch : 0.5778 || loss_t_decoder3/batch : 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  43%|████▎     | 15/35 [00:52<01:07,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2778 || loss_t_decoder2/batch : 0.3565 || loss_t_decoder3/batch : 0.5561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  46%|████▌     | 16/35 [00:55<01:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2011 || loss_t_decoder2/batch : 0.2841 || loss_t_decoder3/batch : 0.5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  49%|████▊     | 17/35 [00:58<01:00,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3032 || loss_t_decoder2/batch : 0.4013 || loss_t_decoder3/batch : 0.5968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  51%|█████▏    | 18/35 [01:02<00:57,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4314 || loss_t_decoder2/batch : 0.5342 || loss_t_decoder3/batch : 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  54%|█████▍    | 19/35 [01:05<00:53,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5792 || loss_t_decoder2/batch : 0.6794 || loss_t_decoder3/batch : 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  57%|█████▋    | 20/35 [01:09<00:50,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5044 || loss_t_decoder2/batch : 0.6088 || loss_t_decoder3/batch : 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  60%|██████    | 21/35 [01:12<00:46,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3510 || loss_t_decoder2/batch : 0.3924 || loss_t_decoder3/batch : 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  63%|██████▎   | 22/35 [01:15<00:43,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4584 || loss_t_decoder2/batch : 0.5110 || loss_t_decoder3/batch : 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  66%|██████▌   | 23/35 [01:19<00:40,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3027 || loss_t_decoder2/batch : 0.4030 || loss_t_decoder3/batch : 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  69%|██████▊   | 24/35 [01:22<00:36,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2543 || loss_t_decoder2/batch : 0.3403 || loss_t_decoder3/batch : 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  71%|███████▏  | 25/35 [01:25<00:33,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3013 || loss_t_decoder2/batch : 0.4499 || loss_t_decoder3/batch : 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  74%|███████▍  | 26/35 [01:29<00:30,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2869 || loss_t_decoder2/batch : 0.4062 || loss_t_decoder3/batch : 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  77%|███████▋  | 27/35 [01:32<00:26,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2831 || loss_t_decoder2/batch : 0.3900 || loss_t_decoder3/batch : 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  80%|████████  | 28/35 [01:35<00:23,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3917 || loss_t_decoder2/batch : 0.4901 || loss_t_decoder3/batch : 0.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  83%|████████▎ | 29/35 [01:39<00:20,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6502 || loss_t_decoder2/batch : 0.7634 || loss_t_decoder3/batch : 0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  86%|████████▌ | 30/35 [01:42<00:16,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2636 || loss_t_decoder2/batch : 0.3760 || loss_t_decoder3/batch : 0.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  89%|████████▊ | 31/35 [01:45<00:13,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.2727 || loss_t_decoder2/batch : 0.4074 || loss_t_decoder3/batch : 0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  91%|█████████▏| 32/35 [01:49<00:10,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3170 || loss_t_decoder2/batch : 0.4353 || loss_t_decoder3/batch : 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  94%|█████████▍| 33/35 [01:52<00:06,  3.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.3726 || loss_t_decoder2/batch : 0.4333 || loss_t_decoder3/batch : 0.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265):  97%|█████████▋| 34/35 [01:56<00:03,  3.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1237 || loss_t_decoder2/batch : 1.1629 || loss_t_decoder3/batch : 1.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 265/265): 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 265: 0.8242535727364676-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           265\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training/\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/4 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  25%|██▌       | 1/4 [00:02<00:08,  2.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.62739497423172\n",
      "Cumulative loss: 0.62739497423172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  50%|█████     | 2/4 [00:03<00:03,  1.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.47877949476242065\n",
      "Cumulative loss: 1.1061744689941406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  75%|███████▌  | 3/4 [00:04<00:01,  1.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6315506100654602\n",
      "Cumulative loss: 1.737725019454956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.43565136194229126\n",
      "Cumulative loss: 2.1733763217926025\n",
      "------Final validation loss after epoch 265: 0.5433440804481506-------------\n",
      "Learning rate after epoch 265: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 265\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'workers': 2,\n",
    "    'epochs': 30,\n",
    "    'train_batch_size': 2,\n",
    "    'val_batch_size': 2,\n",
    "    'test_batch_size': 3,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'data_dir': '/kaggle/input/bratsped/Training/', # Start with Glioma then Menigioma then Metastases\n",
    "                                                    #  then Sub-Saharan Africa and end with Pediatric\n",
    "    'in_checkpoint_dir': Path('/kaggle/input/fine-tuned-model-on-every-population/'),\n",
    "    'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "}\n",
    "trainLoader, valLoader, testLoader = prepare_data_loaders(args)\n",
    "run_model(trainLoader, valLoader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e0815d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T10:57:04.805804Z",
     "iopub.status.busy": "2025-06-08T10:57:04.804150Z",
     "iopub.status.idle": "2025-06-08T10:57:04.810059Z",
     "shell.execute_reply": "2025-06-08T10:57:04.809022Z"
    },
    "papermill": {
     "duration": 0.137907,
     "end_time": "2025-06-08T10:57:04.811879",
     "exception": false,
     "start_time": "2025-06-08T10:57:04.673972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # For freeing gpu\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71795367",
   "metadata": {
    "papermill": {
     "duration": 0.165865,
     "end_time": "2025-06-08T10:57:05.106956",
     "exception": false,
     "start_time": "2025-06-08T10:57:04.941091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d31a5f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T10:57:05.359868Z",
     "iopub.status.busy": "2025-06-08T10:57:05.359496Z",
     "iopub.status.idle": "2025-06-08T10:57:05.364816Z",
     "shell.execute_reply": "2025-06-08T10:57:05.363925Z"
    },
    "papermill": {
     "duration": 0.132575,
     "end_time": "2025-06-08T10:57:05.366494",
     "exception": false,
     "start_time": "2025-06-08T10:57:05.233919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "\n",
    "# class ComputeMetrics(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ComputeMetrics, self).__init__()\n",
    "#         self.dice_metric = DiceMetric(reduction=\"mean_batch\")\n",
    "#         self.hausdorff_metric = HausdorffDistanceMetric(percentile=95.0, reduction=\"mean_batch\")\n",
    "\n",
    "#     def compute(self, p, y, lbl):\n",
    "#         self.dice_metric.reset()\n",
    "#         self.hausdorff_metric.reset()\n",
    "        \n",
    "#         print(f\"{lbl} - Prediction unique values: {torch.unique(p)}\")\n",
    "#         print(f\"{lbl} - Ground truth unique values: {torch.unique(y)}\")\n",
    "\n",
    "#         if torch.sum(y.float()) == 0 and torch.sum(p.float()) == 0:  # True Negative Case: No foreground pixels in GT\n",
    "#             print(f\"{lbl} - No positive samples in ground truth.\")\n",
    "#             print(f\"Dice scores for {lbl} for this batch: {1.0}\")\n",
    "#             print(f\"Hausdorff distances for {lbl} for this batch: {0.0}\")\n",
    "#             return torch.tensor(1.0), torch.tensor(0.0)\n",
    "        \n",
    "#         if torch.sum(p.float()) == 0 and torch.sum(y.float()) > 0:  # False Negative Case: GT has 1s, Prediction is all 0s\n",
    "#             print(f\"{lbl} - False Negative Case: GT has positive samples, but prediction is empty.\")\n",
    "#             print(f\"Dice scores for {lbl} for this batch: {0.0}\")\n",
    "#             print(f\"Hausdorff distances for {lbl} for this batch: {373.1287}\")\n",
    "#             return torch.tensor(0.0), torch.tensor(373.1287)\n",
    "        \n",
    "#         if torch.sum(p.float()) > 0 and torch.sum(y.float()) == 0:  # False Positive Case: Prediction has 1s, GT is all 0s\n",
    "#             print(f\"{lbl} - False Positive Case: Prediction has positives, but ground truth is empty.\")\n",
    "#             print(f\"Dice scores for {lbl} for this batch: {0.0}\")\n",
    "#             print(f\"Hausdorff distances for {lbl} for this batch: {373.1287}\")\n",
    "#             return torch.tensor(0.0), torch.tensor(373.1287)\n",
    "\n",
    "#         # Compute metrics normally\n",
    "#         dice_score = self.dice_metric(p.float(), y.float())\n",
    "#         hausdorff_dist = self.hausdorff_metric(p.float(), y.float())\n",
    "\n",
    "#         print(f\"Dice scores for {lbl} for this batch:\\n {dice_score.item()}\")\n",
    "#         print(f\"Hausdorff distances for {lbl} for this batch:\\n{hausdorff_dist.item()}\")\n",
    "    \n",
    "#         return dice_score, hausdorff_dist\n",
    "\n",
    "#     def forward(self, p, y):\n",
    "#         p = (torch.sigmoid(p) > 0.5)\n",
    "#         y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
    "#         p_wt, p_tc, p_et = p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1), p[:, 3].unsqueeze(1)\n",
    "        \n",
    "#         dice_wt, hd_wt = self.compute(p_wt, y_wt, 'wt')\n",
    "#         dice_tc, hd_tc = self.compute(p_tc, y_tc, 'tc')\n",
    "#         dice_et, hd_et = self.compute(p_et, y_et, 'et')\n",
    "        \n",
    "#         return [dice_wt, hd_wt], [dice_tc, hd_tc], [dice_et, hd_et]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d960bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T10:57:05.616479Z",
     "iopub.status.busy": "2025-06-08T10:57:05.616143Z",
     "iopub.status.idle": "2025-06-08T10:57:05.621875Z",
     "shell.execute_reply": "2025-06-08T10:57:05.621095Z"
    },
    "papermill": {
     "duration": 0.131974,
     "end_time": "2025-06-08T10:57:05.623426",
     "exception": false,
     "start_time": "2025-06-08T10:57:05.491452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_net(model, loader): # student_model, testLoader\n",
    "#     torch.manual_seed(0)\n",
    "#     model.eval()\n",
    "#     n_test_batches = len(loader)\n",
    "\n",
    "#     compute_metrics = ComputeMetrics()\n",
    "#     total_metrics = {\"WT\": {'dice_score': 0, 'hausdorff_distance': 0},\n",
    "#                      \"TC\": {'dice_score': 0, 'hausdorff_distance': 0},\n",
    "#                      \"ET\": {'dice_score': 0, 'hausdorff_distance': 0}}\n",
    "\n",
    "#     with tqdm(total=n_test_batches, desc='Testing', unit='batch', leave=False) as pbar:\n",
    "#         with torch.no_grad():\n",
    "#             for step, y in enumerate(loader):\n",
    "#                 y['imgs'], y['masks']= y['imgs'].to('cuda'), y['masks'].to('cuda')\n",
    "                \n",
    "#                 with torch.amp.autocast('cuda'):\n",
    "#                     print(\"--------Now patient:\", y['patient_id'])\n",
    "#                     output = model(y['imgs'])\n",
    "#                     wt_metrics, tc_metrics, et_metrics = compute_metrics(output['pred'], y['masks'])\n",
    "                    \n",
    "#                     total_metrics['WT']['dice_score'] += wt_metrics[0].item()\n",
    "#                     total_metrics['WT']['hausdorff_distance'] += wt_metrics[1].item()\n",
    "\n",
    "#                     total_metrics['TC']['dice_score'] += tc_metrics[0].item()\n",
    "#                     total_metrics['TC']['hausdorff_distance'] += tc_metrics[1].item()\n",
    "\n",
    "#                     total_metrics['ET']['dice_score'] += et_metrics[0].item()\n",
    "#                     total_metrics['ET']['hausdorff_distance'] += et_metrics[1].item()\n",
    "                                    \n",
    "#                 pbar.update(1)\n",
    "\n",
    "#         total_metrics['WT']['dice_score'] /= n_test_batches\n",
    "#         total_metrics['WT']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "#         total_metrics['TC']['dice_score'] /= n_test_batches\n",
    "#         total_metrics['TC']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "#         total_metrics['ET']['dice_score'] /= n_test_batches\n",
    "#         total_metrics['ET']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "\n",
    "#         print(\"************************************************************************\")\n",
    "#         print(f\"Average Dice Score for WT: {total_metrics['WT']['dice_score']:.4f}\")\n",
    "#         print(f\"Average Hausdorff Distance for WT: {total_metrics['WT']['hausdorff_distance']:.4f}\")\n",
    "\n",
    "#         print(\"-----------------------------------------------------------------------------\")\n",
    "#         print(\"-----------------------------------------------------------------------------\")\n",
    "                                     \n",
    "#         print(f\"Average Dice Score for TC: {total_metrics['TC']['dice_score']:.4f}\")\n",
    "#         print(f\"Average Hausdorff Distance for TC: {total_metrics['TC']['hausdorff_distance']:.4f}\")\n",
    "                              \n",
    "#         print(\"-----------------------------------------------------------------------------\")\n",
    "#         print(\"-----------------------------------------------------------------------------\")\n",
    "                                     \n",
    "#         print(f\"Average Dice Score for ET: {total_metrics['ET']['dice_score']:.4f}\")\n",
    "#         print(f\"Average Hausdorff Distance for ET: {total_metrics['ET']['hausdorff_distance']:.4f}\")\n",
    "#         print(\"************************************************************************\")\n",
    "\n",
    "#         model.train()\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ccd268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T10:57:05.877469Z",
     "iopub.status.busy": "2025-06-08T10:57:05.876725Z",
     "iopub.status.idle": "2025-06-08T10:57:05.881324Z",
     "shell.execute_reply": "2025-06-08T10:57:05.880513Z"
    },
    "papermill": {
     "duration": 0.133838,
     "end_time": "2025-06-08T10:57:05.882984",
     "exception": false,
     "start_time": "2025-06-08T10:57:05.749146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     'workers': 2,\n",
    "#     'epochs': 15,\n",
    "#     'train_batch_size': 2,\n",
    "#     'val_batch_size': 2,\n",
    "#     'test_batch_size': 1,\n",
    "#     'learning_rate': 1e-3,\n",
    "#     'weight_decay': 1e-5,\n",
    "#     'data_dir': '/kaggle/input/bratsglioma/Training/',\n",
    "#     'in_checkpoint_dir': Path('/kaggle/input/glioma75epochs-redlr'),\n",
    "#     'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "# }\n",
    "\n",
    "# _, _, testLoader = prepare_data_loaders(args)\n",
    "# teacher_path = Path(f'/kaggle/input/gliomateachernewlabels/Teacher_model_after_epoch_100_trainLoss_0.5972_valLoss_0.3019.pth')\n",
    "# teacher_model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=False).to('cuda')\n",
    "\n",
    "# if (teacher_path).is_file():\n",
    "#     print(f\"Found model: {teacher_path}\")\n",
    "#     ckpt = torch.load(teacher_path, map_location='cuda', weights_only=True)\n",
    "#     teacher_model.load_state_dict(ckpt['teacher_model'])\n",
    "#     print(f\"Loaded model: {teacher_path}\")\n",
    "#     test_net(teacher_model, testLoader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5906271,
     "sourceId": 9666149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5929819,
     "sourceId": 9697878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5984455,
     "sourceId": 9770532,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6060139,
     "sourceId": 9871878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6235428,
     "sourceId": 10107956,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6329313,
     "sourceId": 10235842,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7584887,
     "sourceId": 12063554,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7599760,
     "sourceId": 12096168,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4072.681015,
   "end_time": "2025-06-08T10:57:08.834242",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-08T09:49:16.153227",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
